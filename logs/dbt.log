[0m08:37:32.727201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D74405D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D7286550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D7507C50>]}


============================== 08:37:32.765471 | e25d3e38-c283-4520-a047-9b9dcd9e5605 ==============================
[0m08:37:32.765471 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:37:32.767475 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'write_json': 'True'}
[0m08:37:33.744346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e25d3e38-c283-4520-a047-9b9dcd9e5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D76B0490>]}
[0m08:37:33.801730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e25d3e38-c283-4520-a047-9b9dcd9e5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D30F05D0>]}
[0m08:37:33.873118 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:37:34.659510 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:37:34.662676 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:37:34.662676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e25d3e38-c283-4520-a047-9b9dcd9e5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D77D7ED0>]}
[0m08:37:39.167865 [info ] [MainThread]: Download variables set: PATH_ROOT=/lakehouse/default, download_limit=288
[0m08:37:39.201314 [error] [MainThread]: Encountered an error:
Compilation Error in operation aemo_electricity-on-run-start-0 (.\dbt_project.yml)
  'None' has no attribute 'table'
[0m08:37:39.204145 [debug] [MainThread]: Command `dbt run` failed at 08:37:39.201314 after 6.57 seconds
[0m08:37:39.204145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D1300050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D7BF2250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000212D11323D0>]}
[0m08:37:39.205815 [debug] [MainThread]: Flushing usage events
[0m08:37:40.387607 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:40:51.661892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDD08810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDD0B450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDD0B690>]}


============================== 08:40:51.671037 | 30b542c7-e133-4c79-9c60-20d895aedf48 ==============================
[0m08:40:51.671037 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:40:51.671037 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False'}
[0m08:40:51.977592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30b542c7-e133-4c79-9c60-20d895aedf48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDE65A50>]}
[0m08:40:52.022486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30b542c7-e133-4c79-9c60-20d895aedf48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9F878A190>]}
[0m08:40:52.038204 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:40:52.417067 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:40:52.419074 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:40:52.422907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '30b542c7-e133-4c79-9c60-20d895aedf48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDDBCDD0>]}
[0m08:40:53.480710 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=288
[0m08:40:53.480710 [error] [MainThread]: Encountered an error:
Compilation Error in operation aemo_electricity-on-run-start-0 (.\dbt_project.yml)
  'None' has no attribute 'data'
[0m08:40:53.497698 [debug] [MainThread]: Command `dbt run` failed at 08:40:53.497698 after 1.92 seconds
[0m08:40:53.498975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDA860D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9F7A40050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9FDD8AD10>]}
[0m08:40:53.500010 [debug] [MainThread]: Flushing usage events
[0m08:40:54.481806 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:41:57.515046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094109AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A09410B7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094107F50>]}


============================== 08:41:57.530836 | e9bfa472-69ad-4753-9391-9b1903af716d ==============================
[0m08:41:57.530836 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:41:57.530836 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m08:41:57.838451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094205E10>]}
[0m08:41:57.886310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A08EC05E50>]}
[0m08:41:57.886310 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:41:58.263237 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:41:58.263237 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:41:58.263237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094414810>]}
[0m08:41:59.365898 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=288
[0m08:41:59.381976 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m08:41:59.381976 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m08:41:59.387669 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m08:41:59.388457 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m08:41:59.388457 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m08:41:59.391553 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m08:41:59.573256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A0941B1B10>]}
[0m08:41:59.652519 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:41:59.684083 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:42:00.355950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094C5ADD0>]}
[0m08:42:00.357958 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:42:00.359964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094A1BAD0>]}
[0m08:42:00.364986 [info ] [MainThread]: 
[0m08:42:00.366994 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:42:00.367905 [info ] [MainThread]: 
[0m08:42:00.368914 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:42:00.376337 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m08:42:09.419910 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m08:42:09.419910 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m08:42:09.419910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:42:12.896553 [debug] [ThreadPool]: SQL status: OK in 3.476 seconds
[0m08:42:12.903172 [debug] [ThreadPool]: On list_ducklake: Close
[0m08:42:12.904185 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m08:42:12.904185 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m08:42:12.904185 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:42:12.904185 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m08:42:12.904185 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:42:12.904185 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m08:42:12.904185 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:42:12.904185 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m08:42:12.904185 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m08:42:12.904185 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:42:12.904185 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m08:42:12.919932 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m08:42:12.919932 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:42:12.919932 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:42:12.919932 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:42:12.935661 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m08:42:12.935661 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m08:42:12.935661 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:42:12.935661 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:42:12.935661 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:42:12.935661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:42:12.935661 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:42:12.935661 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:42:12.935661 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:42:12.983616 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m08:42:12.983616 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:42:12.999754 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:42:12.999754 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:42:12.999754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9bfa472-69ad-4753-9391-9b1903af716d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A0949A4CD0>]}
[0m08:42:12.999754 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:12.999754 [debug] [MainThread]: On master: BEGIN
[0m08:42:12.999754 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:42:12.999754 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:42:12.999754 [debug] [MainThread]: On master: COMMIT
[0m08:42:13.015951 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.015951 [debug] [MainThread]: On master: COMMIT
[0m08:42:13.015951 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:42:13.015951 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=288
[0m08:42:13.015951 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.015951 [debug] [MainThread]: On master: BEGIN
[0m08:42:13.015951 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:42:13.015951 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.015951 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:42:13.029965 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:42:13.029965 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.031806 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 288

[0m08:42:13.031806 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:42:13.034031 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.034414 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:42:13.035213 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:42:13.037312 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:13.037312 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:42:16.162379 [debug] [MainThread]: SQL status: OK in 3.128 seconds
[0m08:42:16.162379 [debug] [MainThread]: Using duckdb connection "master"
[0m08:42:16.162379 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m08:42:16.195403 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m08:42:16.195403 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m08:42:16.203542 [debug] [MainThread]: On master: ROLLBACK
[0m08:42:16.473700 [debug] [MainThread]: Failed to rollback 'master'
[0m08:42:16.473700 [debug] [MainThread]: On master: Close
[0m08:42:16.473700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:42:16.473700 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m08:42:16.477623 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:42:16.477623 [info ] [MainThread]: 
[0m08:42:16.478567 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 16.11 seconds (16.11s).
[0m08:42:16.479574 [error] [MainThread]: Encountered an error:
Runtime Error
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "duckdb_logs"?
  
  LINE 6: WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
                                                             ^
[0m08:42:16.479574 [debug] [MainThread]: Command `dbt run` failed at 08:42:16.479574 after 19.06 seconds
[0m08:42:16.479574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094108F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A08DEC0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A094937450>]}
[0m08:42:16.483439 [debug] [MainThread]: Flushing usage events
[0m08:42:17.469611 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:43:17.281238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D20AED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D20ADD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D20B810>]}


============================== 08:43:17.281238 | 2ec2cb18-02d7-4c26-9c6a-0a763384ec2f ==============================
[0m08:43:17.281238 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:43:17.293950 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m08:43:17.593616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D407590>]}
[0m08:43:17.656752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B07D51CD0>]}
[0m08:43:17.656752 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:43:18.030059 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:43:18.220775 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:43:18.220775 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m08:43:18.322333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D2CA0D0>]}
[0m08:43:18.395819 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:43:18.409256 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:43:18.462553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D87E050>]}
[0m08:43:18.462553 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:43:18.464390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D9F1E10>]}
[0m08:43:18.466397 [info ] [MainThread]: 
[0m08:43:18.466397 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:43:18.468403 [info ] [MainThread]: 
[0m08:43:18.468403 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:43:18.475840 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m08:43:18.749872 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m08:43:18.749872 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m08:43:18.749872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:43:19.125740 [debug] [ThreadPool]: SQL status: OK in 0.379 seconds
[0m08:43:19.131735 [debug] [ThreadPool]: On list_ducklake: Close
[0m08:43:19.131735 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m08:43:19.131735 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m08:43:19.141555 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m08:43:19.141555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:43:19.141555 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m08:43:19.141555 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m08:43:19.141555 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m08:43:19.141555 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m08:43:19.141555 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:43:19.141555 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:43:19.141555 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:43:19.141555 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m08:43:19.157284 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:43:19.163312 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:43:19.163312 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:43:19.163312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:43:19.165320 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:43:19.165320 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:43:19.165320 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:43:19.179095 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m08:43:19.181102 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:43:19.183106 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:43:19.185110 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:43:19.187115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ec2cb18-02d7-4c26-9c6a-0a763384ec2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0D2DE890>]}
[0m08:43:19.188861 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.190867 [debug] [MainThread]: On master: BEGIN
[0m08:43:19.190867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:43:19.192875 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m08:43:19.194879 [debug] [MainThread]: On master: COMMIT
[0m08:43:19.196883 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.196883 [debug] [MainThread]: On master: COMMIT
[0m08:43:19.198887 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:43:19.251419 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=288
[0m08:43:19.251419 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.251419 [debug] [MainThread]: On master: BEGIN
[0m08:43:19.251419 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:43:19.251419 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.251419 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:43:19.251419 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:43:19.251419 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.259767 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 288

[0m08:43:19.259767 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:43:19.259767 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.259767 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:43:19.259767 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:43:19.259767 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.259767 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m08:43:19.259767 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:43:19.267345 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:19.267345 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:43:20.919583 [debug] [MainThread]: SQL status: OK in 1.653 seconds
[0m08:43:20.919583 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.919583 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m08:43:20.935379 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m08:43:20.935379 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.939073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_daily_to_archive = (SELECT count(*) > 0 FROM daily_to_archive)

[0m08:43:20.939073 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m08:43:20.939073 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.939073 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM daily_to_archive)

[0m08:43:20.951360 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m08:43:20.951360 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.951360 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_expected = (SELECT count(*) FROM daily_to_archive)

[0m08:43:20.951360 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:43:20.959419 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.959419 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM daily_to_archive)

[0m08:43:20.963440 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m08:43:20.967072 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m08:43:20.967072 [debug] [MainThread]: Using duckdb connection "master"
[0m08:43:20.967072 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m08:47:39.712355 [debug] [MainThread]: SQL status: OK in 258.742 seconds
[0m08:47:39.716383 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:39.716383 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'daily' AS source_type,
  filename AS source_filename,
  '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM daily_to_archive
WHERE getvariable('daily_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('daily_paths'))) = getvariable('daily_expected')

[0m08:47:39.850252 [debug] [MainThread]: SQL status: OK in 0.132 seconds
[0m08:47:39.852259 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:39.853346 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_scada_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/Dispatch_SCADA/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHSCADA%'
ORDER BY full_url DESC
LIMIT 500

[0m08:47:40.170841 [debug] [MainThread]: SQL status: OK in 0.316 seconds
[0m08:47:40.171456 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.173463 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE scada_today_to_archive AS
SELECT full_url, filename
FROM intraday_scada_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'scada_today')
LIMIT getvariable('download_limit')

[0m08:47:40.173463 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m08:47:40.179239 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.179239 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_scada_today_to_archive = (SELECT count(*) > 0 FROM scada_today_to_archive)

[0m08:47:40.183387 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:47:40.183892 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.186323 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM scada_today_to_archive)

[0m08:47:40.191867 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m08:47:40.195134 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.196141 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_expected = (SELECT count(*) FROM scada_today_to_archive)

[0m08:47:40.198298 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:47:40.200893 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.200893 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM scada_today_to_archive)

[0m08:47:40.209028 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m08:47:40.211783 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m08:47:40.212753 [debug] [MainThread]: Using duckdb connection "master"
[0m08:47:40.214759 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('scada_urls'))
  WHERE getvariable('has_scada_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/scada_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m08:49:47.566154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D108A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D10AC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D10BC10>]}


============================== 08:49:47.584105 | d1628a6e-3efd-48b0-8ba3-d0592c0a9c4b ==============================
[0m08:49:47.584105 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:49:47.584105 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False'}
[0m08:49:48.394239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470BAB26D0>]}
[0m08:49:48.460490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024707C0A350>]}
[0m08:49:48.510790 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:49:49.310301 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:49:49.454252 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:49:49.469892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D1CB490>]}
[0m08:49:54.259365 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m08:49:54.279250 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m08:49:54.478824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D369E10>]}
[0m08:49:54.564193 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:49:54.598683 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:49:55.391258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D98F790>]}
[0m08:49:55.391258 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:49:55.400020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D9FCA50>]}
[0m08:49:55.404056 [info ] [MainThread]: 
[0m08:49:55.407089 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:49:55.408550 [info ] [MainThread]: 
[0m08:49:55.409571 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:49:55.412866 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m08:50:04.870287 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m08:50:04.872010 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m08:50:04.874024 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:50:05.840609 [debug] [ThreadPool]: SQL status: OK in 0.975 seconds
[0m08:50:05.840609 [debug] [ThreadPool]: On list_ducklake: Close
[0m08:50:05.840609 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m08:50:05.840609 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m08:50:05.870613 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:50:05.872371 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m08:50:05.872371 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:50:05.876397 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m08:50:05.880422 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:50:05.880422 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m08:50:05.882437 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:50:05.884448 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:50:05.884448 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m08:50:05.889718 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m08:50:05.895213 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:50:05.895213 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:50:05.895213 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:50:05.897221 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:50:05.897221 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m08:50:05.899228 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:50:05.904041 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:50:05.904041 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:50:05.904041 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:50:05.904041 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m08:50:05.904041 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:50:05.904041 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:50:05.920188 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m08:50:05.920188 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:50:05.968124 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:50:05.968124 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:50:05.968124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1628a6e-3efd-48b0-8ba3-d0592c0a9c4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470DE6A950>]}
[0m08:50:05.968124 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:05.976707 [debug] [MainThread]: On master: BEGIN
[0m08:50:05.976707 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:50:05.978716 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m08:50:05.978716 [debug] [MainThread]: On master: COMMIT
[0m08:50:05.980725 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:05.980725 [debug] [MainThread]: On master: COMMIT
[0m08:50:05.982733 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:50:05.990259 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m08:50:05.990259 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:05.990259 [debug] [MainThread]: On master: BEGIN
[0m08:50:05.990259 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:50:05.990259 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:05.990259 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:50:05.990259 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:50:05.990259 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:05.990259 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m08:50:05.990259 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:50:06.000745 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:06.001671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:50:06.002765 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:50:06.003790 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:06.004860 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m08:50:06.022176 [debug] [MainThread]: SQL status: OK in 0.019 seconds
[0m08:50:06.022176 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:06.022176 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m08:50:06.022176 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:50:06.029526 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:06.030713 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:50:09.915457 [debug] [MainThread]: SQL status: OK in 3.886 seconds
[0m08:50:09.915457 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.915457 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m08:50:09.928040 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m08:50:09.928040 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.928040 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_daily_to_archive = (SELECT count(*) > 0 FROM daily_to_archive)

[0m08:50:09.928040 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:50:09.936234 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.936234 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM daily_to_archive)

[0m08:50:09.936234 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m08:50:09.936234 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.942453 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_expected = (SELECT count(*) FROM daily_to_archive)

[0m08:50:09.942453 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:50:09.944461 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.944461 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM daily_to_archive)

[0m08:50:09.946473 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m08:50:09.946473 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m08:50:09.952137 [debug] [MainThread]: Using duckdb connection "master"
[0m08:50:09.952137 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m08:50:09.952137 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m08:50:09.952137 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m08:50:09.989472 [debug] [MainThread]: On master: ROLLBACK
[0m08:50:10.415630 [debug] [MainThread]: Failed to rollback 'master'
[0m08:50:10.415630 [debug] [MainThread]: On master: Close
[0m08:50:10.415630 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:50:10.415630 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m08:50:10.415630 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:50:10.415630 [info ] [MainThread]: 
[0m08:50:10.415630 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 15.01 seconds (15.01s).
[0m08:50:10.415630 [error] [MainThread]: Encountered an error:
Runtime Error
  IO Error: Failed to create directory "/lakehouse/default/Files/csv/daily": The system cannot find the path specified.
  
[0m08:50:10.415630 [debug] [MainThread]: Command `dbt run` failed at 08:50:10.415630 after 23.03 seconds
[0m08:50:10.415630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470BE86650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D168510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002470D9EFCD0>]}
[0m08:50:10.415630 [debug] [MainThread]: Flushing usage events
[0m08:50:11.495664 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:51:12.215590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF08290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF0ADD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF0B990>]}


============================== 08:51:12.237420 | 823e73d9-9a34-43a5-b6ed-a0926f8ea32b ==============================
[0m08:51:12.237420 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:51:12.237420 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'write_json': 'True'}
[0m08:51:12.558844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5E107D50>]}
[0m08:51:12.601736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF57A5A150>]}
[0m08:51:12.610262 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:51:13.013096 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:51:13.183524 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:51:13.183524 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m08:51:13.185529 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:51:13.215265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF08110>]}
[0m08:51:13.302589 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:51:13.311256 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:51:13.369277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5E10A790>]}
[0m08:51:13.369277 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:51:13.369277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5E6AC0D0>]}
[0m08:51:13.376281 [info ] [MainThread]: 
[0m08:51:13.376281 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:51:13.376281 [info ] [MainThread]: 
[0m08:51:13.379628 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:51:13.386280 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m08:51:13.775594 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m08:51:13.775594 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m08:51:13.775594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:14.209012 [debug] [ThreadPool]: SQL status: OK in 0.432 seconds
[0m08:51:14.215604 [debug] [ThreadPool]: On list_ducklake: Close
[0m08:51:14.216713 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m08:51:14.217772 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m08:51:14.226306 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:14.227356 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m08:51:14.227885 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:51:14.229463 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m08:51:14.230521 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:14.231607 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m08:51:14.232683 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m08:51:14.233205 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:14.233755 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m08:51:14.239641 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m08:51:14.240160 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:51:14.242166 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:14.242166 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:51:14.242166 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:51:14.244172 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m08:51:14.245882 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:51:14.250576 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:51:14.250576 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:51:14.250576 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:14.250576 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:51:14.253645 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:51:14.254001 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:51:14.265104 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m08:51:14.266112 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:51:14.267126 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:51:14.268110 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:51:14.269110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '823e73d9-9a34-43a5-b6ed-a0926f8ea32b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5A835C50>]}
[0m08:51:14.270114 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.271115 [debug] [MainThread]: On master: BEGIN
[0m08:51:14.271115 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:51:14.272115 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:51:14.273137 [debug] [MainThread]: On master: COMMIT
[0m08:51:14.273137 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.273137 [debug] [MainThread]: On master: COMMIT
[0m08:51:14.273137 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:14.298561 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m08:51:14.298561 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.298561 [debug] [MainThread]: On master: BEGIN
[0m08:51:14.303422 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:14.303422 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.304932 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:51:14.305525 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:51:14.305525 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.305525 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m08:51:14.305525 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:14.305525 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.305525 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:51:14.305525 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:14.305525 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.305525 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m08:51:14.320720 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m08:51:14.325536 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.326542 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m08:51:14.329539 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:51:14.331629 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:14.332632 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:51:17.150033 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:51:17.150033 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m08:51:17.150033 [debug] [MainThread]: On master: ROLLBACK
[0m08:51:17.166156 [debug] [MainThread]: Failed to rollback 'master'
[0m08:51:17.168937 [debug] [MainThread]: On master: Close
[0m08:51:17.168937 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:51:17.168937 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m08:51:17.170942 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:51:17.170942 [info ] [MainThread]: 
[0m08:51:17.170942 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 3.79 seconds (3.79s).
[0m08:51:17.170942 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024": 403 (rate limit exceeded).
[0m08:51:17.170942 [debug] [MainThread]: Command `dbt run` failed at 08:51:17.170942 after 5.06 seconds
[0m08:51:17.170942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF56D20710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF6AD50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EF5CF6B0D0>]}
[0m08:51:17.170942 [debug] [MainThread]: Flushing usage events
[0m08:51:18.149198 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:51:46.582953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F50A990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F50ADD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F508C10>]}


============================== 08:51:46.589368 | 801b5c02-3623-48a4-8eeb-2d77c3ff39f1 ==============================
[0m08:51:46.589368 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:51:46.589368 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'target_path': 'None'}
[0m08:51:46.883171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F5C8750>]}
[0m08:51:46.934751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122B0F0610>]}
[0m08:51:46.934751 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:51:47.303149 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:51:47.496471 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:51:47.496471 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m08:51:47.496471 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:51:47.544455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122FA982D0>]}
[0m08:51:47.608393 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:51:47.623992 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:51:47.655688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F5C9690>]}
[0m08:51:47.671656 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:51:47.671656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122FA7F5D0>]}
[0m08:51:47.674766 [info ] [MainThread]: 
[0m08:51:47.674766 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:51:47.674766 [info ] [MainThread]: 
[0m08:51:47.674766 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:51:47.683160 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m08:51:47.953761 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m08:51:47.953761 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m08:51:47.957577 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:48.343246 [debug] [ThreadPool]: SQL status: OK in 0.393 seconds
[0m08:51:48.352284 [debug] [ThreadPool]: On list_ducklake: Close
[0m08:51:48.352284 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m08:51:48.352284 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m08:51:48.358445 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:48.360450 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m08:51:48.360450 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:51:48.360450 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:51:48.362456 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:48.362456 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m08:51:48.364461 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m08:51:48.364461 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:48.364461 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m08:51:48.374400 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m08:51:48.374400 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:51:48.374400 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m08:51:48.374400 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m08:51:48.374400 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:51:48.374400 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m08:51:48.374400 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:51:48.374400 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:51:48.374400 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:51:48.374400 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:48.374400 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m08:51:48.374400 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:51:48.374400 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:51:48.405909 [debug] [ThreadPool]: SQL status: OK in 0.021 seconds
[0m08:51:48.405909 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:51:48.405909 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:51:48.405909 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:51:48.405909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '801b5c02-3623-48a4-8eeb-2d77c3ff39f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F751450>]}
[0m08:51:48.405909 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.405909 [debug] [MainThread]: On master: BEGIN
[0m08:51:48.421637 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:51:48.421637 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m08:51:48.421637 [debug] [MainThread]: On master: COMMIT
[0m08:51:48.424963 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.424963 [debug] [MainThread]: On master: COMMIT
[0m08:51:48.424963 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:48.453229 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m08:51:48.453229 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.453229 [debug] [MainThread]: On master: BEGIN
[0m08:51:48.453229 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:48.453229 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.453229 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:51:48.453229 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:48.453229 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.453229 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m08:51:48.453229 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:48.453229 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.453229 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:51:48.453229 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m08:51:48.453229 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.453229 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m08:51:48.470301 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m08:51:48.471102 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.471102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m08:51:48.473132 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m08:51:48.474159 [debug] [MainThread]: Using duckdb connection "master"
[0m08:51:48.475164 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:51:49.490166 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:51:49.490687 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m08:51:49.493417 [debug] [MainThread]: On master: ROLLBACK
[0m08:51:49.508691 [debug] [MainThread]: Failed to rollback 'master'
[0m08:51:49.509255 [debug] [MainThread]: On master: Close
[0m08:51:49.510634 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:51:49.511246 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m08:51:49.511246 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:51:49.511833 [info ] [MainThread]: 
[0m08:51:49.512895 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m08:51:49.513941 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021": 403 (rate limit exceeded).
[0m08:51:49.516248 [debug] [MainThread]: Command `dbt run` failed at 08:51:49.516248 after 3.02 seconds
[0m08:51:49.517780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122D7E4050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000112292D0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001122F582F90>]}
[0m08:51:49.517780 [debug] [MainThread]: Flushing usage events
[0m08:51:50.480889 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:53:03.377897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF412210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF448850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF4483D0>]}


============================== 08:53:03.393907 | 2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7 ==============================
[0m08:53:03.393907 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:53:03.393907 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'None', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m08:53:03.732598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF4E57D0>]}
[0m08:53:03.776710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BF9E766D0>]}
[0m08:53:03.776710 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:53:04.170622 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:53:04.361341 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:53:04.361341 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m08:53:04.363347 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:53:04.402687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFFA6A750>]}
[0m08:53:04.518278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFFAC4410>]}
[0m08:53:04.518278 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m08:53:04.521973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF98F590>]}
[0m08:53:04.523990 [info ] [MainThread]: 
[0m08:53:04.523990 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:53:04.531328 [info ] [MainThread]: 
[0m08:53:04.533644 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:53:04.537183 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:53:04.753058 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:53:04.753058 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:53:04.753058 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:53:05.127359 [debug] [ThreadPool]: SQL status: OK in 0.374 seconds
[0m08:53:05.127359 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:53:05.127359 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:53:05.161474 [debug] [ThreadPool]: SQL status: OK in 0.029 seconds
[0m08:53:05.161474 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:53:05.161474 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:53:05.161474 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:53:05.161474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a4b5eb3-94f0-4cb9-82ac-b8075f62c6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF98F590>]}
[0m08:53:05.253027 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m08:53:05.254115 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m08:53:05.255028 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m08:53:05.259063 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m08:53:05.259063 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m08:53:05.259063 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m08:53:05.259063 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m08:53:05.259063 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m08:53:05.272123 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m08:53:05.274828 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m08:53:05.274828 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m08:53:05.274828 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m08:53:05.274828 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m08:53:05.274828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m08:53:05.274828 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m08:53:05.274828 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m08:53:05.292935 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m08:53:05.294945 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m08:53:05.294945 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m08:53:05.294945 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m08:53:05.294945 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m08:53:05.354916 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m08:53:05.354916 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m08:53:05.354916 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m08:53:05.354916 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m08:53:05.354916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m08:53:05.354916 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m08:53:05.354916 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m08:53:05.354916 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m08:53:05.354916 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m08:53:05.354916 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m08:53:05.354916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m08:53:05.354916 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m08:53:05.372442 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m08:53:05.372442 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m08:53:05.372442 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m08:53:05.372442 [debug] [Thread-1 (]: Began running node operation.aemo_electricity.aemo_electricity-on-run-start-0
[0m08:53:05.372442 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada_today, now operation.aemo_electricity.aemo_electricity-on-run-start-0)
[0m08:53:05.372442 [debug] [Thread-1 (]: Began compiling node operation.aemo_electricity.aemo_electricity-on-run-start-0
[0m08:53:05.402498 [info ] [Thread-1 (]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m08:53:05.402498 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.402498 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: BEGIN
[0m08:53:05.402498 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:53:05.402498 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m08:53:05.402498 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.402498 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m08:53:05.402498 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m08:53:05.402498 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.402498 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

SET VARIABLE download_limit = 2

[0m08:53:05.402498 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m08:53:05.402498 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.402498 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m08:53:05.402498 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m08:53:05.402498 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.418560 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

USE ducklake.aemo

[0m08:53:05.424787 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m08:53:05.424787 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.424787 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m08:53:05.424787 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m08:53:05.424787 [debug] [Thread-1 (]: Using duckdb connection "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m08:53:05.424787 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:53:06.412562 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "operation.aemo_electricity.aemo_electricity-on-run-start-0"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m08:53:06.414574 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m08:53:06.414574 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: ROLLBACK
[0m08:53:06.488642 [debug] [Thread-1 (]: Failed to rollback 'operation.aemo_electricity.aemo_electricity-on-run-start-0'
[0m08:53:06.488642 [debug] [Thread-1 (]: On operation.aemo_electricity.aemo_electricity-on-run-start-0: Close
[0m08:53:06.488642 [debug] [Thread-1 (]: Runtime Error in operation aemo_electricity-on-run-start-0 (.\dbt_project.yml)
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023": 403 (rate limit exceeded).
[0m08:53:06.488642 [debug] [Thread-1 (]: Finished running node operation.aemo_electricity.aemo_electricity-on-run-start-0
[0m08:53:06.488642 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m08:53:06.488642 [debug] [Thread-4 (]: Marking all children of 'operation.aemo_electricity.aemo_electricity-on-run-start-0' to be skipped because of status 'error'.  Reason: Runtime Error in operation aemo_electricity-on-run-start-0 (.\dbt_project.yml)
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023": 403 (rate limit exceeded)..
[0m08:53:06.488642 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly operation.aemo_electricity.aemo_electricity-on-run-start-0, now model.aemo_electricity.fct_summary)
[0m08:53:06.488642 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_summary
[0m08:53:06.511836 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_summary"
[0m08:53:06.511836 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_summary
[0m08:53:06.511836 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m08:53:06.516683 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:53:06.516683 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:53:06.516683 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_summary' was properly closed.
[0m08:53:06.516683 [error] [MainThread]: Encountered an error:
Runtime Error
  Runtime Error in operation aemo_electricity-on-run-start-0 (.\dbt_project.yml)
    HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023": 403 (rate limit exceeded).
[0m08:53:06.519702 [debug] [MainThread]: Command `dbt docs generate` failed at 08:53:06.519702 after 3.26 seconds
[0m08:53:06.519702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFF46D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFFF0A050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BFFBE4A50>]}
[0m08:53:06.519702 [debug] [MainThread]: Flushing usage events
[0m08:53:07.517766 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:54:27.232909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E8D11D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E8D12850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E8D12450>]}


============================== 08:54:27.236551 | 79f6630f-d1a6-48f2-ba82-444d3bedf64e ==============================
[0m08:54:27.236551 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:54:27.240008 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'None', 'log_format': 'default', 'quiet': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'target_path': 'None'}
[0m08:54:27.549457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E8EB4210>]}
[0m08:54:27.597756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E382EA90>]}
[0m08:54:27.608123 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m08:54:27.997246 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m08:54:28.088440 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:54:28.088440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204EA3C61D0>]}
[0m08:54:29.175898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204EA2A7550>]}
[0m08:54:29.217863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204EA593A10>]}
[0m08:54:29.233737 [info ] [MainThread]: Found 7 models, 1 source, 474 macros
[0m08:54:29.233737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204EA4FE810>]}
[0m08:54:29.233737 [info ] [MainThread]: 
[0m08:54:29.233737 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:54:29.233737 [info ] [MainThread]: 
[0m08:54:29.233737 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m08:54:29.233737 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m08:54:29.440279 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:54:29.440279 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m08:54:29.443770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:29.797360 [debug] [ThreadPool]: SQL status: OK in 0.356 seconds
[0m08:54:29.797360 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m08:54:29.797360 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m08:54:29.823508 [debug] [ThreadPool]: SQL status: OK in 0.027 seconds
[0m08:54:29.823508 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m08:54:29.823508 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m08:54:29.823508 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m08:54:29.823508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79f6630f-d1a6-48f2-ba82-444d3bedf64e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204EA6F3F50>]}
[0m08:54:29.836881 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m08:54:29.836881 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m08:54:29.836881 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m08:54:29.836881 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m08:54:29.852718 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m08:54:29.852718 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m08:54:29.857773 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m08:54:29.857773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m08:54:29.859787 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m08:54:29.867909 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m08:54:29.867909 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m08:54:29.875618 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m08:54:29.877632 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m08:54:29.879645 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m08:54:29.879645 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m08:54:29.893735 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m08:54:29.895744 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m08:54:29.897755 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m08:54:29.899511 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m08:54:29.901524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m08:54:29.901524 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m08:54:29.911587 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m08:54:29.913598 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m08:54:29.915352 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m08:54:29.915352 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m08:54:29.917363 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m08:54:29.917872 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m08:54:29.923895 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m08:54:29.925903 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m08:54:29.927912 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m08:54:29.927912 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m08:54:29.927912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m08:54:29.929921 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m08:54:29.933434 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m08:54:29.935441 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m08:54:29.935441 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m08:54:29.935441 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m08:54:29.935441 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada_today, now model.aemo_electricity.fct_summary)
[0m08:54:29.935441 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_summary
[0m08:54:29.935441 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_summary"
[0m08:54:29.935441 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_summary
[0m08:54:29.935441 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m08:54:29.935441 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:54:29.947420 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m08:54:29.947420 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_summary' was properly closed.
[0m08:54:29.949426 [debug] [MainThread]: Command end result
[0m08:54:30.010742 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:54:30.011228 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:54:30.022452 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\lakehouse\default\Files\dbt\target\run_results.json
[0m08:54:34.036802 [debug] [MainThread]: Acquiring new duckdb connection 'generate_catalog'
[0m08:54:34.036802 [info ] [MainThread]: Building catalog
[0m08:54:34.063535 [debug] [ThreadPool]: Acquiring new duckdb connection 'ducklake.information_schema'
[0m08:54:34.073804 [debug] [ThreadPool]: Using duckdb connection "ducklake.information_schema"
[0m08:54:34.073804 [debug] [ThreadPool]: On ducklake.information_schema: BEGIN
[0m08:54:34.073804 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:34.078976 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m08:54:34.078976 [debug] [ThreadPool]: Using duckdb connection "ducklake.information_schema"
[0m08:54:34.078976 [debug] [ThreadPool]: On ducklake.information_schema: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "ducklake.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'ducklake'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'ducklake'
    )
    select
        'ducklake' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        NULL as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('aemo') or upper(r.schema_name) = upper('bronze'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m08:54:34.098535 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m08:54:34.101430 [debug] [ThreadPool]: On ducklake.information_schema: ROLLBACK
[0m08:54:34.101430 [debug] [ThreadPool]: Failed to rollback 'ducklake.information_schema'
[0m08:54:34.102429 [debug] [ThreadPool]: On ducklake.information_schema: Close
[0m08:54:34.105794 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\lakehouse\default\Files\dbt\target\catalog.json
[0m08:54:34.135047 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m08:54:34.135047 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m08:54:34.135047 [info ] [MainThread]: Catalog written to C:\lakehouse\default\Files\dbt\target\catalog.json
[0m08:54:34.135047 [debug] [MainThread]: Command `dbt docs generate` succeeded at 08:54:34.135047 after 7.02 seconds
[0m08:54:34.135047 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m08:54:34.143857 [debug] [MainThread]: Connection 'ducklake.information_schema' was properly closed.
[0m08:54:34.143857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E8A86790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E29A2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000204E380BB10>]}
[0m08:54:34.143857 [debug] [MainThread]: Flushing usage events
[0m08:54:35.138721 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:18.046983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B314112D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B2DD49090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B31447CD0>]}


============================== 08:55:18.062824 | edc8f926-c0a5-4fde-a4ab-adf90ed6efdd ==============================
[0m08:55:18.062824 [info ] [MainThread]: Running with dbt=1.11.2
[0m08:55:18.062824 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'None', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt docs serve', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'target_path': 'None'}
[0m08:55:18.361987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'edc8f926-c0a5-4fde-a4ab-adf90ed6efdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B314E7590>]}
[0m08:55:18.427071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'edc8f926-c0a5-4fde-a4ab-adf90ed6efdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B2BF1AB50>]}
[0m09:12:38.123311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255CC10B850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255CC10ADD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255CC10BE90>]}


============================== 09:12:38.150113 | a0442ffc-abe2-463d-8d81-6c915fec6935 ==============================
[0m09:12:38.150113 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:12:38.152122 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'write_json': 'True'}
[0m09:12:38.189551 [error] [MainThread]: Encountered an error:
Runtime Error
  Compilation Error
    Could not render abfss://{{ var('fabric_workspace') }}@onelake.dfs.fabric.microsoft.com/{{ var('fabric_lakehouse') }}.Lakehouse/Tables: Required var 'fabric_workspace' not found in config:
    Vars supplied to <Configuration> = {}
[0m09:12:38.191206 [debug] [MainThread]: Command `dbt run` failed at 09:12:38.191206 after 0.18 seconds
[0m09:12:38.192225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255C5EB0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255CAE06250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000255CC111590>]}
[0m09:12:38.193224 [debug] [MainThread]: Flushing usage events
[0m09:12:39.276220 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:14:00.559464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D96B490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D9441D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D944690>]}


============================== 09:14:00.559464 | 409339c3-bcf7-4ea5-819a-3c2da1643454 ==============================
[0m09:14:00.559464 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:14:00.559464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'write_json': 'True'}
[0m09:14:01.541293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D9B39D0>]}
[0m09:14:01.582698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183893EAC10>]}
[0m09:14:01.662124 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:14:02.380923 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:14:02.509086 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:14:02.509086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838B9EE310>]}
[0m09:14:07.100019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838DB38B90>]}
[0m09:14:07.170968 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:14:07.217194 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:14:08.128625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F19EF10>]}
[0m09:14:08.128625 [info ] [MainThread]: Found 7 models, 1 source, 474 macros
[0m09:14:08.135380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F113090>]}
[0m09:14:08.139720 [info ] [MainThread]: 
[0m09:14:08.139720 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:14:08.142075 [info ] [MainThread]: 
[0m09:14:08.143595 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:14:08.147404 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:14:17.295734 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:14:17.295734 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:14:17.295734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:14:18.277756 [debug] [ThreadPool]: SQL status: OK in 0.979 seconds
[0m09:14:18.277756 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:14:18.277756 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:14:18.277756 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:14:18.277756 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:14:18.277756 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:14:18.277756 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:14:18.277756 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m09:14:18.294971 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:14:18.294971 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:14:18.294971 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:14:18.294971 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:14:18.294971 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:14:18.294971 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m09:14:18.294971 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:14:18.294971 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:14:18.294971 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:14:18.294971 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:14:18.294971 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:14:18.310120 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:14:18.310120 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:14:18.310120 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:14:18.310120 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:14:18.310120 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:14:18.310120 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:14:18.310120 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:14:18.330695 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m09:14:18.330695 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:14:18.374141 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:14:18.374141 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:14:18.374141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F1B0FD0>]}
[0m09:14:18.374141 [debug] [MainThread]: Using duckdb connection "master"
[0m09:14:18.384698 [debug] [MainThread]: On master: BEGIN
[0m09:14:18.384698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:14:18.386710 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:14:18.388721 [debug] [MainThread]: On master: COMMIT
[0m09:14:18.390230 [debug] [MainThread]: Using duckdb connection "master"
[0m09:14:18.390230 [debug] [MainThread]: On master: COMMIT
[0m09:14:18.392242 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:14:18.392242 [debug] [MainThread]: On master: Close
[0m09:14:18.516398 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m09:14:18.536739 [info ] [Thread-1 (]: 1 of 7 START sql table model aemo.dim_calendar ................................. [RUN]
[0m09:14:18.536739 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m09:14:18.536739 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m09:14:18.552492 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m09:14:18.553923 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m09:14:18.583633 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_calendar"
[0m09:14:18.583633 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:14:18.583633 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: BEGIN
[0m09:14:18.583633 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:14:18.591803 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:14:18.591803 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:14:18.591803 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_calendar__dbt_tmp"
  
    as (
      

SELECT
  CAST(date AS DATE) as date,
  CAST(EXTRACT(year FROM date) AS INT) as year,
  CAST(EXTRACT(month FROM date) AS INT) as month
FROM (
  SELECT unnest(generate_series(
    CAST('2018-04-01' AS DATE),
    CAST('2026-12-31' AS DATE),
    INTERVAL 1 DAY
  )) as date
)
    );
  
  
[0m09:14:35.008188 [debug] [Thread-1 (]: SQL status: OK in 16.414 seconds
[0m09:14:35.027581 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:14:35.027581 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar__dbt_tmp" rename to "dim_calendar"
[0m09:14:35.034038 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:14:35.062982 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:14:35.064998 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:14:35.067013 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:14:35.122723 [debug] [Thread-1 (]: SQL status: OK in 0.053 seconds
[0m09:14:35.141142 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:14:35.141142 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

      drop table if exists "ducklake"."aemo"."dim_calendar__dbt_backup"
    
[0m09:14:35.234270 [debug] [Thread-1 (]: SQL status: OK in 0.097 seconds
[0m09:14:35.249446 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: Close
[0m09:14:35.287401 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F66ED50>]}
[0m09:14:35.291545 [info ] [Thread-1 (]: 1 of 7 OK created sql table model aemo.dim_calendar ............................ [[32mOK[0m in 16.71s]
[0m09:14:35.295729 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m09:14:35.297468 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m09:14:35.297468 [info ] [Thread-1 (]: 2 of 7 START sql table model aemo.dim_duid ..................................... [RUN]
[0m09:14:35.297468 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m09:14:35.297468 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m09:14:35.313378 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m09:14:35.316169 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m09:14:35.329495 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_duid"
[0m09:14:35.334568 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:14:35.334568 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: BEGIN
[0m09:14:35.334568 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:14:35.345248 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m09:14:35.345248 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:14:35.349573 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_duid__dbt_tmp"
  
    as (
      

WITH
  states AS (
    SELECT 'WA1' AS RegionID, 'Western Australia' AS State
    UNION ALL SELECT 'QLD1', 'Queensland'
    UNION ALL SELECT 'NSW1', 'New South Wales'
    UNION ALL SELECT 'TAS1', 'Tasmania'
    UNION ALL SELECT 'SA1', 'South Australia'
    UNION ALL SELECT 'VIC1', 'Victoria'
  ),

  duid_aemo AS (
    SELECT
      DUID AS DUID,
      first(Region) AS Region,
      first("Fuel Source - Descriptor") AS FuelSourceDescriptor,
      first(Participant) AS Participant
    FROM
      read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
    WHERE
      length(DUID) > 2
    GROUP BY
      DUID
  ),

  wa_facilities AS (
    SELECT
      'WA1' AS Region,
      "Facility Code" AS DUID,
      "Participant Name" AS Participant
    FROM
      read_csv_auto('/lakehouse/default/Files/csv/duid/facilities.csv')
  ),

  wa_energy AS (
    SELECT *
    FROM read_csv_auto('/lakehouse/default/Files/csv/duid/WA_ENERGY.csv', header = 1)
  ),

  duid_wa AS (
    SELECT
      wa_facilities.DUID,
      wa_facilities.Region,
      wa_energy.Technology AS FuelSourceDescriptor,
      wa_facilities.Participant
    FROM wa_facilities
    LEFT JOIN wa_energy ON wa_facilities.DUID = wa_energy.DUID
  ),

  duid_all AS (
    SELECT * FROM duid_aemo
    UNION ALL
    SELECT * FROM duid_wa
  ),

  geo AS (
    SELECT
      duid,
      max(latitude) as latitude,
      max(longitude) as longitude
    FROM read_csv('/lakehouse/default/Files/csv/duid/geo_data.csv')
    WHERE latitude IS NOT NULL
    GROUP BY duid
  )

SELECT
  a.DUID,
  a.Region,
  UPPER(LEFT(TRIM(FuelSourceDescriptor), 1)) || LOWER(SUBSTR(TRIM(FuelSourceDescriptor), 2)) AS FuelSourceDescriptor,
  a.Participant,
  states.State,
  geo.latitude,
  geo.longitude
FROM duid_all a
JOIN states ON a.Region = states.RegionID
LEFT JOIN geo ON a.duid = geo.duid
    );
  
  
[0m09:14:35.362440 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_duid__dbt_tmp"
  
    as (
      

WITH
  states AS (
    SELECT 'WA1' AS RegionID, 'Western Australia' AS State
    UNION ALL SELECT 'QLD1', 'Queensland'
    UNION ALL SELECT 'NSW1', 'New South Wales'
    UNION ALL SELECT 'TAS1', 'Tasmania'
    UNION ALL SELECT 'SA1', 'South Australia'
    UNION ALL SELECT 'VIC1', 'Victoria'
  ),

  duid_aemo AS (
    SELECT
      DUID AS DUID,
      first(Region) AS Region,
      first("Fuel Source - Descriptor") AS FuelSourceDescriptor,
      first(Participant) AS Participant
    FROM
      read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
    WHERE
      length(DUID) > 2
    GROUP BY
      DUID
  ),

  wa_facilities AS (
    SELECT
      'WA1' AS Region,
      "Facility Code" AS DUID,
      "Participant Name" AS Participant
    FROM
      read_csv_auto('/lakehouse/default/Files/csv/duid/facilities.csv')
  ),

  wa_energy AS (
    SELECT *
    FROM read_csv_auto('/lakehouse/default/Files/csv/duid/WA_ENERGY.csv', header = 1)
  ),

  duid_wa AS (
    SELECT
      wa_facilities.DUID,
      wa_facilities.Region,
      wa_energy.Technology AS FuelSourceDescriptor,
      wa_facilities.Participant
    FROM wa_facilities
    LEFT JOIN wa_energy ON wa_facilities.DUID = wa_energy.DUID
  ),

  duid_all AS (
    SELECT * FROM duid_aemo
    UNION ALL
    SELECT * FROM duid_wa
  ),

  geo AS (
    SELECT
      duid,
      max(latitude) as latitude,
      max(longitude) as longitude
    FROM read_csv('/lakehouse/default/Files/csv/duid/geo_data.csv')
    WHERE latitude IS NOT NULL
    GROUP BY duid
  )

SELECT
  a.DUID,
  a.Region,
  UPPER(LEFT(TRIM(FuelSourceDescriptor), 1)) || LOWER(SUBSTR(TRIM(FuelSourceDescriptor), 2)) AS FuelSourceDescriptor,
  a.Participant,
  states.State,
  geo.latitude,
  geo.longitude
FROM duid_all a
JOIN states ON a.Region = states.RegionID
LEFT JOIN geo ON a.duid = geo.duid
    );
  
  
[0m09:14:35.362440 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:14:35.362440 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: ROLLBACK
[0m09:14:35.756307 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.dim_duid'
[0m09:14:35.756307 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: Close
[0m09:14:35.772532 [debug] [Thread-1 (]: Runtime Error in model dim_duid (models\dimensions\dim_duid.sql)
  IO Error: No files found that match the pattern "/lakehouse/default/Files/csv/duid/duid_data.csv"
  
  LINE 30:       read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
                 ^
[0m09:14:35.772532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F176610>]}
[0m09:14:35.772532 [error] [Thread-1 (]: 2 of 7 ERROR creating sql table model aemo.dim_duid ............................ [[31mERROR[0m in 0.48s]
[0m09:14:35.788405 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m09:14:35.788405 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m09:14:35.788405 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.dim_duid' to be skipped because of status 'error'.  Reason: Runtime Error in model dim_duid (models\dimensions\dim_duid.sql)
  IO Error: No files found that match the pattern "/lakehouse/default/Files/csv/duid/duid_data.csv"
  
  LINE 30:       read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
                 ^.
[0m09:14:35.788405 [info ] [Thread-1 (]: 3 of 7 START sql incremental model aemo.fct_price .............................. [RUN]
[0m09:14:35.797327 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m09:14:35.797327 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m09:14:35.816006 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m09:14:35.819858 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m09:14:35.867604 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price"
[0m09:14:35.883562 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:14:35.886923 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: BEGIN
[0m09:14:35.888929 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:14:35.888929 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:14:35.888929 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:14:35.888929 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:14:35.910680 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:14:35.912687 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:14:35.915267 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: ROLLBACK
[0m09:14:35.915267 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price'
[0m09:14:35.915267 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: Close
[0m09:14:35.915267 [debug] [Thread-1 (]: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:35.915267 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F66F9D0>]}
[0m09:14:35.915267 [error] [Thread-1 (]: 3 of 7 ERROR creating sql incremental model aemo.fct_price ..................... [[31mERROR[0m in 0.12s]
[0m09:14:35.930932 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m09:14:35.930932 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m09:14:35.930932 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^.
[0m09:14:35.935637 [info ] [Thread-1 (]: 4 of 7 START sql incremental model aemo.fct_price_today ........................ [RUN]
[0m09:14:35.935637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m09:14:35.935637 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m09:14:35.946934 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m09:14:35.946934 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m09:14:35.962755 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price_today"
[0m09:14:35.962755 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:14:35.962755 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: BEGIN
[0m09:14:35.969535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:14:35.971549 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m09:14:35.971549 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:14:35.977327 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:14:35.980850 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:14:35.994896 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:14:35.994896 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: ROLLBACK
[0m09:14:35.999402 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price_today'
[0m09:14:35.999402 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: Close
[0m09:14:35.999402 [debug] [Thread-1 (]: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:35.999402 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F84D450>]}
[0m09:14:36.011043 [error] [Thread-1 (]: 4 of 7 ERROR creating sql incremental model aemo.fct_price_today ............... [[31mERROR[0m in 0.06s]
[0m09:14:36.013831 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m09:14:36.013831 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m09:14:36.013831 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^.
[0m09:14:36.013831 [info ] [Thread-1 (]: 5 of 7 START sql incremental model aemo.fct_scada .............................. [RUN]
[0m09:14:36.013831 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m09:14:36.013831 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m09:14:36.013831 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m09:14:36.029289 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m09:14:36.042893 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada"
[0m09:14:36.042893 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:14:36.042893 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: BEGIN
[0m09:14:36.042893 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:14:36.051844 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m09:14:36.053855 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:14:36.055868 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:14:36.069705 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:14:36.069705 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:14:36.069705 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: ROLLBACK
[0m09:14:36.074889 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada'
[0m09:14:36.074889 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: Close
[0m09:14:36.083845 [debug] [Thread-1 (]: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.083845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F894210>]}
[0m09:14:36.083845 [error] [Thread-1 (]: 5 of 7 ERROR creating sql incremental model aemo.fct_scada ..................... [[31mERROR[0m in 0.07s]
[0m09:14:36.083845 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m09:14:36.083845 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m09:14:36.083845 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^.
[0m09:14:36.083845 [info ] [Thread-1 (]: 6 of 7 START sql incremental model aemo.fct_scada_today ........................ [RUN]
[0m09:14:36.090760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m09:14:36.090760 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m09:14:36.090760 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m09:14:36.090760 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m09:14:36.106679 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada_today"
[0m09:14:36.106679 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:14:36.113540 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: BEGIN
[0m09:14:36.114556 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:14:36.114556 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m09:14:36.114556 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:14:36.114556 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:14:36.139360 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."bronze"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:14:36.141438 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:14:36.142459 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: ROLLBACK
[0m09:14:36.147449 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada_today'
[0m09:14:36.147449 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: Close
[0m09:14:36.158630 [debug] [Thread-1 (]: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.160643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '409339c3-bcf7-4ea5-819a-3c2da1643454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838F864190>]}
[0m09:14:36.164685 [error] [Thread-1 (]: 6 of 7 ERROR creating sql incremental model aemo.fct_scada_today ............... [[31mERROR[0m in 0.07s]
[0m09:14:36.164685 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m09:14:36.164685 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m09:14:36.170421 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^.
[0m09:14:36.170421 [info ] [Thread-1 (]: 7 of 7 SKIP relation aemo.fct_summary .......................................... [[33mSKIP[0m]
[0m09:14:36.170421 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m09:14:36.178424 [debug] [MainThread]: Using duckdb connection "master"
[0m09:14:36.178424 [debug] [MainThread]: On master: BEGIN
[0m09:14:36.178424 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:14:36.178424 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:14:36.186387 [debug] [MainThread]: On master: COMMIT
[0m09:14:36.186387 [debug] [MainThread]: Using duckdb connection "master"
[0m09:14:36.186387 [debug] [MainThread]: On master: COMMIT
[0m09:14:36.186387 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:14:36.194509 [debug] [MainThread]: On master: Close
[0m09:14:36.194509 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:14:36.198623 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:14:36.198623 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:14:36.200533 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_scada_today' was properly closed.
[0m09:14:36.200533 [info ] [MainThread]: 
[0m09:14:36.200533 [info ] [MainThread]: Finished running 5 incremental models, 2 table models in 0 hours 0 minutes and 28.06 seconds (28.06s).
[0m09:14:36.206065 [debug] [MainThread]: Command end result
[0m09:14:36.257604 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:14:36.273360 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:14:36.273360 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\lakehouse\default\Files\dbt\target\run_results.json
[0m09:14:36.273360 [info ] [MainThread]: 
[0m09:14:36.286732 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m09:14:36.289010 [info ] [MainThread]: 
[0m09:14:36.289010 [error] [MainThread]: [31mFailure in model dim_duid (models\dimensions\dim_duid.sql)[0m
[0m09:14:36.293688 [error] [MainThread]:   Runtime Error in model dim_duid (models\dimensions\dim_duid.sql)
  IO Error: No files found that match the pattern "/lakehouse/default/Files/csv/duid/duid_data.csv"
  
  LINE 30:       read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
                 ^
[0m09:14:36.293688 [info ] [MainThread]: 
[0m09:14:36.293688 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\dimensions\dim_duid.sql
[0m09:14:36.293688 [info ] [MainThread]: 
[0m09:14:36.305027 [error] [MainThread]: [31mFailure in model fct_price (models\marts\fct_price.sql)[0m
[0m09:14:36.305027 [error] [MainThread]:   Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.309573 [info ] [MainThread]: 
[0m09:14:36.311585 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price.sql
[0m09:14:36.311585 [info ] [MainThread]: 
[0m09:14:36.314873 [error] [MainThread]: [31mFailure in model fct_price_today (models\marts\fct_price_today.sql)[0m
[0m09:14:36.314873 [error] [MainThread]:   Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.314873 [info ] [MainThread]: 
[0m09:14:36.320670 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price_today.sql
[0m09:14:36.320670 [info ] [MainThread]: 
[0m09:14:36.320670 [error] [MainThread]: [31mFailure in model fct_scada (models\marts\fct_scada.sql)[0m
[0m09:14:36.320670 [error] [MainThread]:   Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.328278 [info ] [MainThread]: 
[0m09:14:36.328278 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada.sql
[0m09:14:36.328278 [info ] [MainThread]: 
[0m09:14:36.332780 [error] [MainThread]: [31mFailure in model fct_scada_today (models\marts\fct_scada_today.sql)[0m
[0m09:14:36.334696 [error] [MainThread]:   Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "information_schema.constraint_column_usage"?
  
  LINE 17:   FROM "ducklake"."bronze"."csv_archive_log"
                  ^
[0m09:14:36.336208 [info ] [MainThread]: 
[0m09:14:36.336208 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada_today.sql
[0m09:14:36.336208 [info ] [MainThread]: 
[0m09:14:36.336208 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=5 SKIP=1 NO-OP=0 TOTAL=7
[0m09:14:36.345502 [debug] [MainThread]: Command `dbt run` failed at 09:14:36.345502 after 35.89 seconds
[0m09:14:36.345502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D969490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183876D0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001838D982650>]}
[0m09:14:36.351174 [debug] [MainThread]: Flushing usage events
[0m09:14:37.591826 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:19:29.826326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B308450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B30B510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B3089D0>]}


============================== 09:19:29.826326 | 23d73b2e-4878-44c8-825b-cda09932dd7e ==============================
[0m09:19:29.826326 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:19:29.840178 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'use_experimental_parser': 'False'}
[0m09:19:30.140776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B507450>]}
[0m09:19:30.203426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025045E0DC50>]}
[0m09:19:30.203426 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:19:30.592526 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:19:30.657516 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:19:30.657516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504949E110>]}
[0m09:19:31.701852 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:19:31.715774 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m09:19:31.717526 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m09:19:31.718343 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m09:19:31.719351 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m09:19:31.720753 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m09:19:31.721760 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m09:19:31.898258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504BD50190>]}
[0m09:19:31.975609 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:19:31.993976 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:19:32.059094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504BCA6350>]}
[0m09:19:32.059094 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:19:32.059094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B56A450>]}
[0m09:19:32.067284 [info ] [MainThread]: 
[0m09:19:32.069292 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:19:32.070798 [info ] [MainThread]: 
[0m09:19:32.070798 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:19:32.070798 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:19:32.303710 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:19:32.303710 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:19:32.303710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:32.697656 [debug] [ThreadPool]: SQL status: OK in 0.392 seconds
[0m09:19:32.697656 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:19:32.700189 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:19:32.700189 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:19:32.702841 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:19:32.702841 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:19:32.702841 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:19:32.702841 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:19:32.702841 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:19:32.702841 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:19:32.713479 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:19:32.713479 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:19:32.713479 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:19:32.720475 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m09:19:32.725651 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:19:32.725651 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:19:32.727659 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:19:32.729410 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:19:32.729940 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:19:32.729940 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:19:32.742314 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:19:32.743314 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:19:32.744297 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:19:32.746914 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:19:32.748008 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:19:32.748942 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:19:32.780583 [debug] [ThreadPool]: SQL status: OK in 0.033 seconds
[0m09:19:32.780583 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:19:32.786738 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:19:32.786738 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:19:32.786738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23d73b2e-4878-44c8-825b-cda09932dd7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B31F910>]}
[0m09:19:32.786738 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.793274 [debug] [MainThread]: On master: BEGIN
[0m09:19:32.793274 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:19:32.795284 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:19:32.796293 [debug] [MainThread]: On master: COMMIT
[0m09:19:32.796293 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.798300 [debug] [MainThread]: On master: COMMIT
[0m09:19:32.798300 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:19:32.810344 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:19:32.810344 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.812092 [debug] [MainThread]: On master: BEGIN
[0m09:19:32.812092 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:19:32.812092 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.812092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m09:19:32.812092 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:19:32.812092 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.812092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m09:19:32.812092 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:19:32.812092 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.812092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m09:19:32.812092 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:19:32.812092 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.812092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m09:19:32.834993 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m09:19:32.834993 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.834993 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m09:19:32.834993 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:19:32.834993 [debug] [MainThread]: Using duckdb connection "master"
[0m09:19:32.834993 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m09:19:33.858946 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m09:19:33.858946 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m09:19:33.863657 [debug] [MainThread]: On master: ROLLBACK
[0m09:19:33.954006 [debug] [MainThread]: Failed to rollback 'master'
[0m09:19:33.954006 [debug] [MainThread]: On master: Close
[0m09:19:33.954006 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:19:33.954006 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:19:33.954006 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:19:33.969991 [info ] [MainThread]: 
[0m09:19:33.969991 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 1.90 seconds (1.90s).
[0m09:19:33.969991 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020": 403 (rate limit exceeded).
[0m09:19:33.976673 [debug] [MainThread]: Command `dbt run` failed at 09:19:33.976673 after 4.25 seconds
[0m09:19:33.976673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B333E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000250450D0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002504B086650>]}
[0m09:19:33.976673 [debug] [MainThread]: Flushing usage events
[0m09:19:34.984577 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:28:05.525323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1A70AED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1A70ADD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1A70BC10>]}


============================== 09:28:05.533170 | 3547f6e9-bda3-4b10-b6cb-c382ee5ae06b ==============================
[0m09:28:05.533170 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:28:05.534815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m09:28:05.847156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1A7DD6D0>]}
[0m09:28:05.889160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C161EC990>]}
[0m09:28:05.889160 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:28:06.282900 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:28:06.375064 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:28:06.375064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1889E290>]}
[0m09:28:07.450323 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] Daily source: aemo
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m09:28:07.450986 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m09:28:07.658409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C16485490>]}
[0m09:28:07.732315 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:28:07.738351 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:28:07.774097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C04B390>]}
[0m09:28:07.774097 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:28:07.782142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C013B90>]}
[0m09:28:07.782142 [info ] [MainThread]: 
[0m09:28:07.782142 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:28:07.782142 [info ] [MainThread]: 
[0m09:28:07.782142 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:28:07.795877 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:28:07.996198 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:28:07.996198 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:28:07.996198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:28:08.403296 [debug] [ThreadPool]: SQL status: OK in 0.406 seconds
[0m09:28:08.403296 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:28:08.406958 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:28:08.406958 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:28:08.406958 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:28:08.406958 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:28:08.406958 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:28:08.417624 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:28:08.419667 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:28:08.419667 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:28:08.420658 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:28:08.421632 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:28:08.421632 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:28:08.425738 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m09:28:08.425738 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:28:08.425738 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:28:08.425738 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:28:08.425738 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:28:08.425738 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:28:08.433225 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:28:08.435236 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:28:08.435236 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:28:08.435236 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:28:08.441387 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:28:08.441387 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:28:08.441387 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:28:08.459486 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m09:28:08.459486 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:28:08.459486 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:28:08.459486 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:28:08.459486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1AF2A410>]}
[0m09:28:08.459486 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.459486 [debug] [MainThread]: On master: BEGIN
[0m09:28:08.459486 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:28:08.469863 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:08.469863 [debug] [MainThread]: On master: COMMIT
[0m09:28:08.469863 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.469863 [debug] [MainThread]: On master: COMMIT
[0m09:28:08.471877 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:28:08.478673 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:28:08.480688 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.480688 [debug] [MainThread]: On master: BEGIN
[0m09:28:08.482729 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:28:08.482729 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.482729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m09:28:08.484744 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:28:08.484744 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.484744 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m09:28:08.484744 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:28:08.489172 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.490017 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m09:28:08.492501 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:08.493983 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.495423 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m09:28:08.503018 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m09:28:08.506456 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.506456 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m09:28:08.506456 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:08.509832 [info ] [MainThread]: [DOWNLOAD] Daily source: aemo
[0m09:28:08.509832 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.512610 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('https://nemweb.com.au/Reports/Current/Daily_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'https://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DAILY%.zip%'
ORDER BY full_url DESC

[0m09:28:08.672659 [debug] [MainThread]: SQL status: OK in 0.160 seconds
[0m09:28:08.674669 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.674669 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m09:28:08.676679 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:28:08.678689 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.678689 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_daily_to_archive = (SELECT count(*) > 0 FROM daily_to_archive)

[0m09:28:08.680697 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:08.680697 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.680697 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM daily_to_archive)

[0m09:28:08.684717 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:28:08.686468 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.686468 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_expected = (SELECT count(*) FROM daily_to_archive)

[0m09:28:08.688473 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:08.688473 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.691388 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM daily_to_archive)

[0m09:28:08.693395 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:28:08.695758 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m09:28:08.697766 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:08.697766 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:28:09.301774 [debug] [MainThread]: SQL status: OK in 0.607 seconds
[0m09:28:09.301774 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:09.301774 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'daily' AS source_type,
  filename AS source_filename,
  '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM daily_to_archive
WHERE getvariable('daily_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('daily_paths'))) = getvariable('daily_expected')

[0m09:28:25.506343 [debug] [MainThread]: SQL status: OK in 16.207 seconds
[0m09:28:25.506343 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:25.506343 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_scada_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/Dispatch_SCADA/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHSCADA%'
ORDER BY full_url DESC
LIMIT 500

[0m09:28:25.680700 [debug] [MainThread]: SQL status: OK in 0.175 seconds
[0m09:28:25.696481 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:25.696481 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE scada_today_to_archive AS
SELECT full_url, filename
FROM intraday_scada_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'scada_today')
LIMIT getvariable('download_limit')

[0m09:28:28.450473 [debug] [MainThread]: SQL status: OK in 2.751 seconds
[0m09:28:28.450473 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.450473 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_scada_today_to_archive = (SELECT count(*) > 0 FROM scada_today_to_archive)

[0m09:28:28.450473 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:28:28.463044 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.463044 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM scada_today_to_archive)

[0m09:28:28.463044 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:28:28.463044 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.463044 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_expected = (SELECT count(*) FROM scada_today_to_archive)

[0m09:28:28.463044 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:28:28.477952 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.479963 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM scada_today_to_archive)

[0m09:28:28.481972 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m09:28:28.487538 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m09:28:28.487538 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.489546 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('scada_urls'))
  WHERE getvariable('has_scada_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/scada_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:28:28.632959 [debug] [MainThread]: SQL status: OK in 0.153 seconds
[0m09:28:28.632959 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:28.632959 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'scada_today' AS source_type,
  filename AS source_filename,
  '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM scada_today_to_archive
WHERE getvariable('scada_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('scada_paths'))) = getvariable('scada_expected')

[0m09:28:34.489279 [debug] [MainThread]: SQL status: OK in 5.845 seconds
[0m09:28:34.489279 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:34.489279 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_price_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/DispatchIS_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHIS_%.zip%'
ORDER BY full_url DESC
LIMIT 500

[0m09:28:34.676294 [debug] [MainThread]: SQL status: OK in 0.179 seconds
[0m09:28:34.676294 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:34.676294 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE price_today_to_archive AS
SELECT full_url, filename
FROM intraday_price_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'price_today')
LIMIT getvariable('download_limit')

[0m09:28:36.930748 [debug] [MainThread]: SQL status: OK in 2.252 seconds
[0m09:28:36.930748 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:36.930748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_price_today_to_archive = (SELECT count(*) > 0 FROM price_today_to_archive)

[0m09:28:36.930748 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:36.930748 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:36.930748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM price_today_to_archive)

[0m09:28:36.940331 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:28:36.940331 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:36.940331 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_expected = (SELECT count(*) FROM price_today_to_archive)

[0m09:28:36.940331 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:28:36.940331 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:36.940331 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM price_today_to_archive)

[0m09:28:36.947414 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:28:36.947414 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m09:28:36.947414 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:36.947414 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('price_urls'))
  WHERE getvariable('has_price_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/price_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:28:37.126289 [debug] [MainThread]: SQL status: OK in 0.174 seconds
[0m09:28:37.131856 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:37.133869 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'price_today' AS source_type,
  filename AS source_filename,
  '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM price_today_to_archive
WHERE getvariable('price_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('price_paths'))) = getvariable('price_expected')

[0m09:28:42.114583 [debug] [MainThread]: SQL status: OK in 4.979 seconds
[0m09:28:42.116588 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m09:28:42.118592 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:42.120597 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (SELECT 1 AS id, 'init' AS dummy) TO (getvariable('csv_archive_path') || '/duid')
(FORMAT csv, PARTITION_BY (dummy), FILE_EXTENSION 'csv', OVERWRITE_OR_IGNORE)

[0m09:28:42.135422 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m09:28:42.135422 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:42.135422 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/djouallah-patch-1/duid_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/duid_data.csv') (FORMAT CSV, HEADER)

[0m09:28:42.518641 [debug] [MainThread]: SQL status: OK in 0.384 seconds
[0m09:28:42.518641 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:42.518641 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://data.wa.aemo.com.au/datafiles/post-facilities/facilities.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/facilities.csv') (FORMAT CSV, HEADER)

[0m09:28:43.545781 [debug] [MainThread]: SQL status: OK in 1.036 seconds
[0m09:28:43.561895 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:43.565787 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/WA_ENERGY.csv', header=true, null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/WA_ENERGY.csv') (FORMAT CSV, HEADER)

[0m09:28:43.868788 [debug] [MainThread]: SQL status: OK in 0.301 seconds
[0m09:28:43.873922 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:43.875937 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/geo_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/geo_data.csv') (FORMAT CSV, HEADER)

[0m09:28:44.171191 [debug] [MainThread]: SQL status: OK in 0.303 seconds
[0m09:28:44.171191 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:44.186859 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

DELETE FROM csv_archive_log WHERE source_type LIKE 'duid_%'

[0m09:28:46.477847 [debug] [MainThread]: SQL status: OK in 2.291 seconds
[0m09:28:46.477847 [debug] [MainThread]: Using duckdb connection "master"
[0m09:28:46.477847 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT * FROM (VALUES
  ('duid_data', 'duid_data', '/duid/duid_data.csv', now()),
  ('duid_facilities', 'facilities', '/duid/facilities.csv', now()),
  ('duid_wa_energy', 'WA_ENERGY', '/duid/WA_ENERGY.csv', now()),
  ('duid_geo_data', 'geo_data', '/duid/geo_data.csv', now())
) AS t(source_type, source_filename, archive_path, archived_at)

[0m09:28:52.153521 [debug] [MainThread]: SQL status: OK in 5.672 seconds
[0m09:28:52.157552 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m09:28:52.161575 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m09:28:52.163589 [debug] [MainThread]: Writing injected SQL for node "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m09:28:52.181956 [info ] [MainThread]: 1 of 1 START hook: aemo_electricity.on-run-start.0 ............................. [RUN]
[0m09:28:52.183951 [info ] [MainThread]: 1 of 1 OK hook: aemo_electricity.on-run-start.0 ................................ [[32mOK[0m in 43.71s]
[0m09:28:52.185951 [info ] [MainThread]: 
[0m09:28:52.187741 [debug] [MainThread]: On master: ROLLBACK
[0m09:28:52.190780 [debug] [MainThread]: Failed to rollback 'master'
[0m09:28:52.192455 [debug] [MainThread]: On master: Close
[0m09:29:02.504990 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m09:29:02.504990 [info ] [Thread-1 (]: 1 of 7 START sql table model aemo.dim_calendar ................................. [RUN]
[0m09:29:02.504990 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m09:29:02.504990 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m09:29:02.526762 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m09:29:02.530986 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m09:29:02.570963 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_calendar"
[0m09:29:02.570963 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:02.570963 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: BEGIN
[0m09:29:02.570963 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:29:02.570963 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:29:02.570963 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:02.570963 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_calendar__dbt_tmp"
  
    as (
      

SELECT
  CAST(date AS DATE) as date,
  CAST(EXTRACT(year FROM date) AS INT) as year,
  CAST(EXTRACT(month FROM date) AS INT) as month
FROM (
  SELECT unnest(generate_series(
    CAST('2018-04-01' AS DATE),
    CAST('2026-12-31' AS DATE),
    INTERVAL 1 DAY
  )) as date
)
    );
  
  
[0m09:29:06.144412 [debug] [Thread-1 (]: SQL status: OK in 3.572 seconds
[0m09:29:06.160298 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.160298 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

    SELECT index_name
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_calendar'
  
[0m09:29:06.176173 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m09:29:06.176173 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.176173 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

    SELECT COUNT(*) as remaining_indexes
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_calendar'
  
[0m09:29:06.176173 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:29:06.193676 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.193676 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar" rename to "dim_calendar__dbt_backup"
[0m09:29:06.193676 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:29:06.204291 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.205379 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar__dbt_tmp" rename to "dim_calendar"
[0m09:29:06.207018 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:29:06.227658 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:29:06.229197 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.229527 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:29:06.252865 [debug] [Thread-1 (]: SQL status: OK in 0.023 seconds
[0m09:29:06.259743 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:29:06.259743 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

      drop table if exists "ducklake"."aemo"."dim_calendar__dbt_backup"
    
[0m09:29:06.307425 [debug] [Thread-1 (]: SQL status: OK in 0.047 seconds
[0m09:29:06.310624 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: Close
[0m09:29:06.313660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C5A6410>]}
[0m09:29:06.314761 [info ] [Thread-1 (]: 1 of 7 OK created sql table model aemo.dim_calendar ............................ [[32mOK[0m in 3.81s]
[0m09:29:06.315956 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m09:29:06.315956 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m09:29:06.317032 [info ] [Thread-1 (]: 2 of 7 START sql table model aemo.dim_duid ..................................... [RUN]
[0m09:29:06.317737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m09:29:06.318792 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m09:29:06.323081 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m09:29:06.325042 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m09:29:06.328631 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_duid"
[0m09:29:06.331632 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:29:06.331632 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: BEGIN
[0m09:29:06.332631 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:06.334632 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:29:06.335920 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:29:06.336943 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_duid__dbt_tmp"
  
    as (
      

WITH
  states AS (
    SELECT 'WA1' AS RegionID, 'Western Australia' AS State
    UNION ALL SELECT 'QLD1', 'Queensland'
    UNION ALL SELECT 'NSW1', 'New South Wales'
    UNION ALL SELECT 'TAS1', 'Tasmania'
    UNION ALL SELECT 'SA1', 'South Australia'
    UNION ALL SELECT 'VIC1', 'Victoria'
  ),

  duid_aemo AS (
    SELECT
      DUID AS DUID,
      first(Region) AS Region,
      first("Fuel Source - Descriptor") AS FuelSourceDescriptor,
      first(Participant) AS Participant
    FROM
      read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
    WHERE
      length(DUID) > 2
    GROUP BY
      DUID
  ),

  wa_facilities AS (
    SELECT
      'WA1' AS Region,
      "Facility Code" AS DUID,
      "Participant Name" AS Participant
    FROM
      read_csv_auto('/lakehouse/default/Files/csv/duid/facilities.csv')
  ),

  wa_energy AS (
    SELECT *
    FROM read_csv_auto('/lakehouse/default/Files/csv/duid/WA_ENERGY.csv', header = 1)
  ),

  duid_wa AS (
    SELECT
      wa_facilities.DUID,
      wa_facilities.Region,
      wa_energy.Technology AS FuelSourceDescriptor,
      wa_facilities.Participant
    FROM wa_facilities
    LEFT JOIN wa_energy ON wa_facilities.DUID = wa_energy.DUID
  ),

  duid_all AS (
    SELECT * FROM duid_aemo
    UNION ALL
    SELECT * FROM duid_wa
  ),

  geo AS (
    SELECT
      duid,
      max(latitude) as latitude,
      max(longitude) as longitude
    FROM read_csv('/lakehouse/default/Files/csv/duid/geo_data.csv')
    WHERE latitude IS NOT NULL
    GROUP BY duid
  )

SELECT
  a.DUID,
  a.Region,
  UPPER(LEFT(TRIM(FuelSourceDescriptor), 1)) || LOWER(SUBSTR(TRIM(FuelSourceDescriptor), 2)) AS FuelSourceDescriptor,
  a.Participant,
  states.State,
  geo.latitude,
  geo.longitude
FROM duid_all a
JOIN states ON a.Region = states.RegionID
LEFT JOIN geo ON a.duid = geo.duid
    );
  
  
[0m09:29:10.819187 [debug] [Thread-1 (]: SQL status: OK in 4.488 seconds
[0m09:29:10.827874 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:29:10.827874 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */
alter table "ducklake"."aemo"."dim_duid__dbt_tmp" rename to "dim_duid"
[0m09:29:10.827874 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:29:10.827874 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:29:10.833249 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:29:10.833249 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:29:10.856885 [debug] [Thread-1 (]: SQL status: OK in 0.024 seconds
[0m09:29:10.861135 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:29:10.861135 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

      drop table if exists "ducklake"."aemo"."dim_duid__dbt_backup"
    
[0m09:29:10.894501 [debug] [Thread-1 (]: SQL status: OK in 0.037 seconds
[0m09:29:10.894501 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: Close
[0m09:29:10.894501 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C6B4110>]}
[0m09:29:10.902821 [info ] [Thread-1 (]: 2 of 7 OK created sql table model aemo.dim_duid ................................ [[32mOK[0m in 4.58s]
[0m09:29:10.902821 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m09:29:10.902821 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m09:29:10.902821 [info ] [Thread-1 (]: 3 of 7 START sql incremental model aemo.fct_price .............................. [RUN]
[0m09:29:10.902821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m09:29:10.902821 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m09:29:10.913109 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m09:29:10.915356 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m09:29:10.952525 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price"
[0m09:29:10.954236 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:29:10.954236 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: BEGIN
[0m09:29:10.954236 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:10.954236 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:29:10.954236 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:29:10.961550 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:29:10.971587 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:29:10.972592 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:29:10.973591 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: ROLLBACK
[0m09:29:10.986128 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price'
[0m09:29:10.986128 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: Close
[0m09:29:10.991895 [debug] [Thread-1 (]: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:10.991895 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1AC75CD0>]}
[0m09:29:10.994133 [error] [Thread-1 (]: 3 of 7 ERROR creating sql incremental model aemo.fct_price ..................... [[31mERROR[0m in 0.09s]
[0m09:29:10.994569 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m09:29:10.994569 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m09:29:10.994569 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:29:10.994569 [info ] [Thread-1 (]: 4 of 7 START sql incremental model aemo.fct_price_today ........................ [RUN]
[0m09:29:10.994569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m09:29:10.994569 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m09:29:11.003722 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m09:29:11.005728 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m09:29:11.008730 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price_today"
[0m09:29:11.008730 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:29:11.012290 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: BEGIN
[0m09:29:11.012753 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:11.015397 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:29:11.015397 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:29:11.015397 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:29:11.026833 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:29:11.027412 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:29:11.028417 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: ROLLBACK
[0m09:29:11.034176 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price_today'
[0m09:29:11.035767 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: Close
[0m09:29:11.036779 [debug] [Thread-1 (]: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.036779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C6C6010>]}
[0m09:29:11.044474 [error] [Thread-1 (]: 4 of 7 ERROR creating sql incremental model aemo.fct_price_today ............... [[31mERROR[0m in 0.04s]
[0m09:29:11.044474 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m09:29:11.044474 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m09:29:11.044474 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:29:11.044474 [info ] [Thread-1 (]: 5 of 7 START sql incremental model aemo.fct_scada .............................. [RUN]
[0m09:29:11.044474 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m09:29:11.044474 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m09:29:11.056336 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m09:29:11.059282 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m09:29:11.063315 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada"
[0m09:29:11.070020 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:29:11.070949 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: BEGIN
[0m09:29:11.071991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:11.072957 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:29:11.074047 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:29:11.074047 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:29:11.085673 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:29:11.085673 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:29:11.086685 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: ROLLBACK
[0m09:29:11.090099 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada'
[0m09:29:11.090099 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: Close
[0m09:29:11.096714 [debug] [Thread-1 (]: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.096714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C0A3D10>]}
[0m09:29:11.096714 [error] [Thread-1 (]: 5 of 7 ERROR creating sql incremental model aemo.fct_scada ..................... [[31mERROR[0m in 0.05s]
[0m09:29:11.096714 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m09:29:11.096714 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m09:29:11.096714 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:29:11.102465 [info ] [Thread-1 (]: 6 of 7 START sql incremental model aemo.fct_scada_today ........................ [RUN]
[0m09:29:11.102992 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m09:29:11.102992 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m09:29:11.107165 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m09:29:11.110702 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m09:29:11.117007 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada_today"
[0m09:29:11.120068 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:29:11.122077 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: BEGIN
[0m09:29:11.122437 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:11.123300 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m09:29:11.127380 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:29:11.129070 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:29:11.141637 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:29:11.143652 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:29:11.145029 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: ROLLBACK
[0m09:29:11.145029 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada_today'
[0m09:29:11.145029 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: Close
[0m09:29:11.152931 [debug] [Thread-1 (]: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.152931 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3547f6e9-bda3-4b10-b6cb-c382ee5ae06b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C1C6C1410>]}
[0m09:29:11.152931 [error] [Thread-1 (]: 6 of 7 ERROR creating sql incremental model aemo.fct_scada_today ............... [[31mERROR[0m in 0.05s]
[0m09:29:11.152931 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m09:29:11.152931 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m09:29:11.152931 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:29:11.152931 [info ] [Thread-1 (]: 7 of 7 SKIP relation aemo.fct_summary .......................................... [[33mSKIP[0m]
[0m09:29:11.152931 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m09:29:11.161099 [debug] [MainThread]: Using duckdb connection "master"
[0m09:29:11.161099 [debug] [MainThread]: On master: BEGIN
[0m09:29:11.161099 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:29:11.161099 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:29:11.161099 [debug] [MainThread]: On master: COMMIT
[0m09:29:11.161099 [debug] [MainThread]: Using duckdb connection "master"
[0m09:29:11.161099 [debug] [MainThread]: On master: COMMIT
[0m09:29:11.161099 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:29:11.161099 [debug] [MainThread]: On master: Close
[0m09:29:11.169488 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:29:11.170306 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:29:11.171319 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:29:11.171319 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_scada_today' was properly closed.
[0m09:29:11.172336 [info ] [MainThread]: 
[0m09:29:11.173174 [info ] [MainThread]: Finished running 5 incremental models, 1 project hook, 2 table models in 0 hours 1 minutes and 3.39 seconds (63.39s).
[0m09:29:11.175225 [debug] [MainThread]: Command end result
[0m09:29:11.269712 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:29:11.278220 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:29:11.286644 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\lakehouse\default\Files\dbt\target\run_results.json
[0m09:29:11.286644 [info ] [MainThread]: 
[0m09:29:11.292165 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m09:29:11.292165 [info ] [MainThread]: 
[0m09:29:11.292165 [error] [MainThread]: [31mFailure in model fct_price (models\marts\fct_price.sql)[0m
[0m09:29:11.294419 [error] [MainThread]:   Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.294419 [info ] [MainThread]: 
[0m09:29:11.294419 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price.sql
[0m09:29:11.297173 [info ] [MainThread]: 
[0m09:29:11.298182 [error] [MainThread]: [31mFailure in model fct_price_today (models\marts\fct_price_today.sql)[0m
[0m09:29:11.299184 [error] [MainThread]:   Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.300187 [info ] [MainThread]: 
[0m09:29:11.301749 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price_today.sql
[0m09:29:11.302265 [info ] [MainThread]: 
[0m09:29:11.303276 [error] [MainThread]: [31mFailure in model fct_scada (models\marts\fct_scada.sql)[0m
[0m09:29:11.304274 [error] [MainThread]:   Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.305271 [info ] [MainThread]: 
[0m09:29:11.306302 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada.sql
[0m09:29:11.307271 [info ] [MainThread]: 
[0m09:29:11.308272 [error] [MainThread]: [31mFailure in model fct_scada_today (models\marts\fct_scada_today.sql)[0m
[0m09:29:11.310623 [error] [MainThread]:   Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:29:11.311645 [info ] [MainThread]: 
[0m09:29:11.312646 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada_today.sql
[0m09:29:11.313984 [info ] [MainThread]: 
[0m09:29:11.313984 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=4 SKIP=1 NO-OP=0 TOTAL=8
[0m09:29:11.313984 [debug] [MainThread]: Command `dbt run` failed at 09:29:11.313984 after 65.91 seconds
[0m09:29:11.319121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C144C0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C11E923D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C11E92410>]}
[0m09:29:11.320136 [debug] [MainThread]: Flushing usage events
[0m09:29:12.645897 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:34:16.539673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D27750BB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D27750B510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D27750BC10>]}


============================== 09:34:16.550346 | 4b44ab73-0352-408e-87a4-799c33cf61b4 ==============================
[0m09:34:16.550346 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:34:16.550346 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False'}
[0m09:34:17.127893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b44ab73-0352-408e-87a4-799c33cf61b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2775E23D0>]}
[0m09:34:17.232331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b44ab73-0352-408e-87a4-799c33cf61b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2730F8590>]}
[0m09:34:17.239024 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:34:18.270970 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:34:18.684894 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:34:18.684894 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m09:34:18.717533 [error] [MainThread]: Encountered an error:
Compilation Error
  Encountered unknown tag 'endmacro'. You probably made a nesting mistake. Jinja is expecting this tag, but currently looking for 'elif' or 'else' or 'endif'. The innermost block that needs to be closed is 'if'.
    line 347
      {% endmacro %}
[0m09:34:18.723217 [debug] [MainThread]: Command `dbt run` failed at 09:34:18.723217 after 2.29 seconds
[0m09:34:18.725231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D2712F0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D277187E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D277507750>]}
[0m09:34:18.727244 [debug] [MainThread]: Flushing usage events
[0m09:34:19.827534 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:35:05.616826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023289B6AC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023289B697D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023289B68ED0>]}


============================== 09:35:05.625007 | 1c27cf4d-03fd-473b-8480-2b8ad38e1b65 ==============================
[0m09:35:05.625007 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:35:05.625007 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False'}
[0m09:35:05.932288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023284880750>]}
[0m09:35:05.980965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232845C8C50>]}
[0m09:35:05.993449 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:35:06.378146 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:35:06.617687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:35:06.617687 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m09:35:06.714132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023289DB3210>]}
[0m09:35:06.794298 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:35:06.794298 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:35:06.875302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002328B091CD0>]}
[0m09:35:06.877324 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:35:06.878834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002328B0B7B10>]}
[0m09:35:06.880840 [info ] [MainThread]: 
[0m09:35:06.880840 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:35:06.880840 [info ] [MainThread]: 
[0m09:35:06.880840 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:35:06.892820 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:35:07.479230 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:35:07.479230 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:35:07.479230 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:07.894298 [debug] [ThreadPool]: SQL status: OK in 0.417 seconds
[0m09:35:07.894298 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:35:07.894298 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:35:07.894298 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:35:07.904282 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:07.904282 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:35:07.904282 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:35:07.904282 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m09:35:07.920064 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:07.920064 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:35:07.920064 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:35:07.920064 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:07.920064 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:35:07.936154 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m09:35:07.936154 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:35:07.936154 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:07.936154 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:35:07.936154 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:35:07.936154 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:35:07.951875 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:35:07.951875 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:35:07.967857 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:35:07.967857 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:07.967857 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m09:35:07.967857 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:35:07.967857 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:35:08.005320 [debug] [ThreadPool]: SQL status: OK in 0.029 seconds
[0m09:35:08.007329 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:35:08.009337 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:35:08.011345 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:35:08.013353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c27cf4d-03fd-473b-8480-2b8ad38e1b65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002328B15DB50>]}
[0m09:35:08.015105 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.015105 [debug] [MainThread]: On master: BEGIN
[0m09:35:08.017761 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:35:08.019770 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:35:08.019770 [debug] [MainThread]: On master: COMMIT
[0m09:35:08.021779 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.021779 [debug] [MainThread]: On master: COMMIT
[0m09:35:08.023788 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:35:08.062693 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=288
[0m09:35:08.062693 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.062693 [debug] [MainThread]: On master: BEGIN
[0m09:35:08.062693 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:35:08.062693 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.062693 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m09:35:08.062693 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:35:08.079819 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.079819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 288

[0m09:35:08.079819 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:35:08.079819 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.079819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m09:35:08.079819 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:35:08.079819 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:08.079819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m09:35:09.139167 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

[0m09:35:09.139167 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m09:35:09.139167 [debug] [MainThread]: On master: ROLLBACK
[0m09:35:09.177492 [debug] [MainThread]: Failed to rollback 'master'
[0m09:35:09.179102 [debug] [MainThread]: On master: Close
[0m09:35:09.181109 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:35:09.181615 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:35:09.182841 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:35:09.183851 [info ] [MainThread]: 
[0m09:35:09.185849 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 2.30 seconds (2.30s).
[0m09:35:09.186848 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024": 403 (rate limit exceeded).
[0m09:35:09.189722 [debug] [MainThread]: Command `dbt run` failed at 09:35:09.189722 after 3.66 seconds
[0m09:35:09.190728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023283930050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002328B6A1B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023289B44090>]}
[0m09:35:09.191612 [debug] [MainThread]: Flushing usage events
[0m09:35:10.220799 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:35:53.428760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F080AE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F0809090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F080BC10>]}


============================== 09:35:53.428760 | da453d79-db37-41d1-a38f-b2467dc236f3 ==============================
[0m09:35:53.428760 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:35:53.428760 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'write_json': 'True'}
[0m09:35:53.753918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F08C92D0>]}
[0m09:35:53.817502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EC3F8290>]}
[0m09:35:53.817502 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:35:54.219091 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:35:54.415035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:35:54.415035 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m09:35:54.513557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F0E5C410>]}
[0m09:35:54.596958 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:35:54.609094 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:35:54.657126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F08E1090>]}
[0m09:35:54.657126 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:35:54.657126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F0A2B210>]}
[0m09:35:54.657126 [info ] [MainThread]: 
[0m09:35:54.657126 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:35:54.657126 [info ] [MainThread]: 
[0m09:35:54.657126 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:35:54.657126 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:35:55.301813 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:35:55.304202 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:35:55.304202 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:55.702727 [debug] [ThreadPool]: SQL status: OK in 0.398 seconds
[0m09:35:55.704744 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:35:55.706252 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:35:55.706252 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:35:55.712542 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:55.712542 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:35:55.712542 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:35:55.714547 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:35:55.716554 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:55.716554 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:35:55.716554 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:35:55.716554 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:55.718559 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:35:55.721968 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m09:35:55.721968 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:35:55.725583 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:35:55.725583 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:35:55.727588 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:35:55.727588 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:35:55.729806 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:35:55.733561 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:35:55.733561 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:35:55.735566 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:55.735566 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:35:55.735566 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:35:55.737571 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:35:55.753304 [debug] [ThreadPool]: SQL status: OK in 0.021 seconds
[0m09:35:55.753304 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:35:55.753304 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:35:55.753304 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:35:55.769112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da453d79-db37-41d1-a38f-b2467dc236f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F08DE990>]}
[0m09:35:55.769112 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:55.769112 [debug] [MainThread]: On master: BEGIN
[0m09:35:55.769112 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:35:55.769112 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:35:55.769112 [debug] [MainThread]: On master: COMMIT
[0m09:35:55.769112 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:55.769112 [debug] [MainThread]: On master: COMMIT
[0m09:35:55.769112 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:35:55.785168 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:55.801074 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

    
SET VARIABLE PATH_ROOT = '/lakehouse/default';
SET VARIABLE download_limit = 288;
SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv';

  
[0m09:35:55.801074 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:35:55.801074 [info ] [MainThread]: Download variables set: PATH_ROOT=/lakehouse/default, download_limit=288
[0m09:35:55.801074 [debug] [MainThread]: Using duckdb connection "master"
[0m09:35:55.801074 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

    
CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

  
[0m09:35:56.832908 [debug] [MainThread]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

    
CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  api_responses AS (
    SELECT 2018 AS year, content AS json_content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2018')
    UNION ALL SELECT 2019, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2019')
    UNION ALL SELECT 2020, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2020')
    UNION ALL SELECT 2021, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2021')
    UNION ALL SELECT 2022, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2022')
    UNION ALL SELECT 2023, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2023')
    UNION ALL SELECT 2024, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2024')
    UNION ALL SELECT 2025, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2025')
    UNION ALL SELECT 2026, content FROM read_text('https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026')
  ),
  parsed_files AS (
    SELECT year, unnest(from_json(json_content, '["json"]')) AS file_info
    FROM api_responses
  )
SELECT
  json_extract_string(file_info, '$.download_url') AS full_url,
  split_part(json_extract_string(file_info, '$.name'), '.', 1) AS filename
FROM parsed_files
WHERE json_extract_string(file_info, '$.name') LIKE 'PUBLIC_DAILY%.zip'
ORDER BY full_url DESC

  
[0m09:35:56.832908 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m09:35:56.832908 [debug] [MainThread]: On master: Close
[0m09:35:56.832908 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:35:56.832908 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:35:56.832908 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:35:56.832908 [info ] [MainThread]: 
[0m09:35:56.832908 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 2.18 seconds (2.18s).
[0m09:35:56.832908 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTP Error: Unable to connect to URL "https://api.github.com/repos/djouallah/fabric_demo/contents/data/archive/2026": 403 (rate limit exceeded).
[0m09:35:56.832908 [debug] [MainThread]: Command `dbt run` failed at 09:35:56.832908 after 3.52 seconds
[0m09:35:56.832908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F0888810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6EA6D0710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D6F0586650>]}
[0m09:35:56.832908 [debug] [MainThread]: Flushing usage events
[0m09:35:57.863973 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:37:49.837748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F607D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F60B9D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F608C90>]}


============================== 09:37:49.837748 | 21a65ef8-4a8c-474a-ba5a-59e1cf0f7e12 ==============================
[0m09:37:49.837748 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:37:49.837748 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'no_print': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'use_experimental_parser': 'False'}
[0m09:37:50.160016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21a65ef8-4a8c-474a-ba5a-59e1cf0f7e12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F763AD0>]}
[0m09:37:50.211383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21a65ef8-4a8c-474a-ba5a-59e1cf0f7e12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1B0F8810>]}
[0m09:37:50.213388 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:37:50.588454 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:37:50.864433 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:37:50.866439 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m09:37:50.874457 [error] [MainThread]: Encountered an error:
Compilation Error
  Encountered unknown tag 'endmacro'. You probably made a nesting mistake. Jinja is expecting this tag, but currently looking for 'elif' or 'else' or 'endif'. The innermost block that needs to be closed is 'if'.
    line 347
      {% endmacro %}
[0m09:37:50.874457 [debug] [MainThread]: Command `dbt run` failed at 09:37:50.874457 after 1.14 seconds
[0m09:37:50.874457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C16F70050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F386650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C1F287E50>]}
[0m09:37:50.874457 [debug] [MainThread]: Flushing usage events
[0m09:37:51.921554 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:38:40.207110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487A08850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487A0BAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487A0A3D0>]}


============================== 09:38:40.217356 | 2cf082c1-67c3-433b-a02c-3f73efb055b3 ==============================
[0m09:38:40.217356 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:38:40.219105 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'use_experimental_parser': 'False'}
[0m09:38:40.586566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487B7FE10>]}
[0m09:38:40.639204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027483500610>]}
[0m09:38:40.643425 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:38:41.079528 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:38:41.301453 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:38:41.303459 [debug] [MainThread]: Partial parsing: updated file: aemo_electricity://macros\download.sql
[0m09:38:41.401255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000274890B5FD0>]}
[0m09:38:41.486022 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:38:41.486022 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:38:41.550030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027485336110>]}
[0m09:38:41.550030 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:38:41.550030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002748534DAD0>]}
[0m09:38:41.550030 [info ] [MainThread]: 
[0m09:38:41.550030 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:38:41.550030 [info ] [MainThread]: 
[0m09:38:41.550030 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:38:41.567588 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:38:41.828664 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:38:41.828664 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:38:41.828664 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:42.223043 [debug] [ThreadPool]: SQL status: OK in 0.394 seconds
[0m09:38:42.223043 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:38:42.223043 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:38:42.223043 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:38:42.223043 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:38:42.239111 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:38:42.239111 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:38:42.239111 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:38:42.242647 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:38:42.242647 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:38:42.242647 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:38:42.242647 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:38:42.242647 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:38:42.242647 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m09:38:42.242647 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:38:42.242647 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:38:42.242647 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:38:42.242647 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:38:42.254979 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:38:42.254979 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:38:42.258736 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:38:42.258736 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:38:42.258736 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:38:42.258736 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:38:42.258736 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:38:42.258736 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:38:42.280015 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m09:38:42.280015 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:38:42.286757 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:38:42.286757 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:38:42.289341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027485387850>]}
[0m09:38:42.289341 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.289341 [debug] [MainThread]: On master: BEGIN
[0m09:38:42.289341 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:38:42.289341 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:38:42.289341 [debug] [MainThread]: On master: COMMIT
[0m09:38:42.289341 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.289341 [debug] [MainThread]: On master: COMMIT
[0m09:38:42.289341 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:38:42.321951 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:38:42.323043 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.323677 [debug] [MainThread]: On master: BEGIN
[0m09:38:42.324752 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:38:42.325373 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.326084 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m09:38:42.326688 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:38:42.326688 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.326688 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m09:38:42.326688 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:38:42.330904 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.331408 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m09:38:42.332738 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:38:42.334390 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.334916 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE SCHEMA IF NOT EXISTS ducklake.aemo

[0m09:38:42.340345 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m09:38:42.340345 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.340345 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m09:38:42.340345 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:38:42.340345 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.340345 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS ducklake.aemo.csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m09:38:42.345567 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:38:42.345567 [info ] [MainThread]: [DOWNLOAD] Daily source: aemo
[0m09:38:42.345567 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.345567 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('https://nemweb.com.au/Reports/Current/Daily_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'https://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DAILY%.zip%'
ORDER BY full_url DESC

[0m09:38:42.512044 [debug] [MainThread]: SQL status: OK in 0.162 seconds
[0m09:38:42.514055 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.514055 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m09:38:42.514055 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:38:42.514055 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.524130 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_daily_to_archive = (SELECT count(*) > 0 FROM daily_to_archive)

[0m09:38:42.528153 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:38:42.528153 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.528153 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM daily_to_archive)

[0m09:38:42.539877 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m09:38:42.539877 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.539877 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_expected = (SELECT count(*) FROM daily_to_archive)

[0m09:38:42.539877 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:38:42.539877 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.539877 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM daily_to_archive)

[0m09:38:42.555612 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m09:38:42.555612 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m09:38:42.555612 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:42.555612 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:38:43.246762 [debug] [MainThread]: SQL status: OK in 0.689 seconds
[0m09:38:43.246762 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:43.246762 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'daily' AS source_type,
  filename AS source_filename,
  '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM daily_to_archive
WHERE getvariable('daily_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('daily_paths'))) = getvariable('daily_expected')

[0m09:38:52.863331 [debug] [MainThread]: SQL status: OK in 9.612 seconds
[0m09:38:52.863331 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:52.871410 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_scada_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/Dispatch_SCADA/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHSCADA%'
ORDER BY full_url DESC
LIMIT 500

[0m09:38:53.089201 [debug] [MainThread]: SQL status: OK in 0.216 seconds
[0m09:38:53.089201 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:53.089201 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE scada_today_to_archive AS
SELECT full_url, filename
FROM intraday_scada_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'scada_today')
LIMIT getvariable('download_limit')

[0m09:38:55.947636 [debug] [MainThread]: SQL status: OK in 2.852 seconds
[0m09:38:55.949652 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:55.951411 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_scada_today_to_archive = (SELECT count(*) > 0 FROM scada_today_to_archive)

[0m09:38:55.955442 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:38:55.957935 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:55.959951 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM scada_today_to_archive)

[0m09:38:55.968494 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m09:38:55.968494 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:55.968494 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_expected = (SELECT count(*) FROM scada_today_to_archive)

[0m09:38:55.968494 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:38:55.980724 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:55.980724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM scada_today_to_archive)

[0m09:38:55.992530 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m09:38:55.997859 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m09:38:55.999865 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:56.000864 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('scada_urls'))
  WHERE getvariable('has_scada_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/scada_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:38:56.145176 [debug] [MainThread]: SQL status: OK in 0.143 seconds
[0m09:38:56.147663 [debug] [MainThread]: Using duckdb connection "master"
[0m09:38:56.147663 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'scada_today' AS source_type,
  filename AS source_filename,
  '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM scada_today_to_archive
WHERE getvariable('scada_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('scada_paths'))) = getvariable('scada_expected')

[0m09:39:01.846074 [debug] [MainThread]: SQL status: OK in 5.709 seconds
[0m09:39:01.846074 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:01.861985 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_price_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/DispatchIS_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHIS_%.zip%'
ORDER BY full_url DESC
LIMIT 500

[0m09:39:02.038649 [debug] [MainThread]: SQL status: OK in 0.174 seconds
[0m09:39:02.041219 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:02.042307 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE price_today_to_archive AS
SELECT full_url, filename
FROM intraday_price_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'price_today')
LIMIT getvariable('download_limit')

[0m09:39:04.823510 [debug] [MainThread]: SQL status: OK in 2.782 seconds
[0m09:39:04.826326 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:04.826326 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_price_today_to_archive = (SELECT count(*) > 0 FROM price_today_to_archive)

[0m09:39:04.828331 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:39:04.828331 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:04.830338 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM price_today_to_archive)

[0m09:39:04.830338 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:39:04.830338 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:04.830338 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_expected = (SELECT count(*) FROM price_today_to_archive)

[0m09:39:04.830338 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:39:04.830338 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:04.838647 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM price_today_to_archive)

[0m09:39:04.839679 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:39:04.839679 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m09:39:04.844160 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:04.844160 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('price_urls'))
  WHERE getvariable('has_price_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/price_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:39:05.027658 [debug] [MainThread]: SQL status: OK in 0.182 seconds
[0m09:39:05.030677 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:05.032680 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'price_today' AS source_type,
  filename AS source_filename,
  '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM price_today_to_archive
WHERE getvariable('price_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('price_paths'))) = getvariable('price_expected')

[0m09:39:10.216882 [debug] [MainThread]: SQL status: OK in 5.183 seconds
[0m09:39:10.216882 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m09:39:10.216882 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:10.216882 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (SELECT 1 AS id, 'init' AS dummy) TO (getvariable('csv_archive_path') || '/duid')
(FORMAT csv, PARTITION_BY (dummy), FILE_EXTENSION 'csv', OVERWRITE_OR_IGNORE)

[0m09:39:10.232599 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m09:39:10.237224 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:10.239085 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/djouallah-patch-1/duid_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/duid_data.csv') (FORMAT CSV, HEADER)

[0m09:39:10.554947 [debug] [MainThread]: SQL status: OK in 0.313 seconds
[0m09:39:10.558960 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:10.560569 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://data.wa.aemo.com.au/datafiles/post-facilities/facilities.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/facilities.csv') (FORMAT CSV, HEADER)

[0m09:39:10.839786 [debug] [MainThread]: SQL status: OK in 0.276 seconds
[0m09:39:10.843819 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:10.845834 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/WA_ENERGY.csv', header=true, null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/WA_ENERGY.csv') (FORMAT CSV, HEADER)

[0m09:39:11.120263 [debug] [MainThread]: SQL status: OK in 0.271 seconds
[0m09:39:11.122673 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:11.125155 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/geo_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/geo_data.csv') (FORMAT CSV, HEADER)

[0m09:39:11.427910 [debug] [MainThread]: SQL status: OK in 0.302 seconds
[0m09:39:11.430668 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:11.432681 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

DELETE FROM csv_archive_log WHERE source_type LIKE 'duid_%'

[0m09:39:13.714034 [debug] [MainThread]: SQL status: OK in 2.280 seconds
[0m09:39:13.714034 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:13.714034 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT * FROM (VALUES
  ('duid_data', 'duid_data', '/duid/duid_data.csv', now()),
  ('duid_facilities', 'facilities', '/duid/facilities.csv', now()),
  ('duid_wa_energy', 'WA_ENERGY', '/duid/WA_ENERGY.csv', now()),
  ('duid_geo_data', 'geo_data', '/duid/geo_data.csv', now())
) AS t(source_type, source_filename, archive_path, archived_at)

[0m09:39:19.599643 [debug] [MainThread]: SQL status: OK in 5.882 seconds
[0m09:39:19.603672 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m09:39:19.606858 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m09:39:19.608937 [debug] [MainThread]: Writing injected SQL for node "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m09:39:19.623618 [info ] [MainThread]: 1 of 1 START hook: aemo_electricity.on-run-start.0 ............................. [RUN]
[0m09:39:19.626818 [info ] [MainThread]: 1 of 1 OK hook: aemo_electricity.on-run-start.0 ................................ [[32mOK[0m in 37.34s]
[0m09:39:19.628744 [info ] [MainThread]: 
[0m09:39:19.630752 [debug] [MainThread]: On master: ROLLBACK
[0m09:39:19.633736 [debug] [MainThread]: Failed to rollback 'master'
[0m09:39:19.634983 [debug] [MainThread]: On master: Close
[0m09:39:30.213388 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m09:39:30.213388 [info ] [Thread-1 (]: 1 of 7 START sql table model aemo.dim_calendar ................................. [RUN]
[0m09:39:30.221944 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m09:39:30.221944 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m09:39:30.230255 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m09:39:30.233414 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m09:39:30.262924 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_calendar"
[0m09:39:30.262924 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:30.267442 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: BEGIN
[0m09:39:30.267442 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:39:30.269470 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:39:30.269470 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:30.270759 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_calendar__dbt_tmp"
  
    as (
      

SELECT
  CAST(date AS DATE) as date,
  CAST(EXTRACT(year FROM date) AS INT) as year,
  CAST(EXTRACT(month FROM date) AS INT) as month
FROM (
  SELECT unnest(generate_series(
    CAST('2018-04-01' AS DATE),
    CAST('2026-12-31' AS DATE),
    INTERVAL 1 DAY
  )) as date
)
    );
  
  
[0m09:39:34.091057 [debug] [Thread-1 (]: SQL status: OK in 3.824 seconds
[0m09:39:34.100353 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.100353 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

    SELECT index_name
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_calendar'
  
[0m09:39:34.107362 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:34.107362 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.107362 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

    SELECT COUNT(*) as remaining_indexes
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_calendar'
  
[0m09:39:34.107362 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:39:34.115612 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.115612 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar" rename to "dim_calendar__dbt_backup"
[0m09:39:34.123570 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:39:34.126913 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.128921 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar__dbt_tmp" rename to "dim_calendar"
[0m09:39:34.128921 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:39:34.150414 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:39:34.150414 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.150414 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:39:34.176233 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m09:39:34.183496 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:39:34.184459 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

      drop table if exists "ducklake"."aemo"."dim_calendar__dbt_backup"
    
[0m09:39:34.235524 [debug] [Thread-1 (]: SQL status: OK in 0.051 seconds
[0m09:39:34.238613 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: Close
[0m09:39:34.241617 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000274894D2190>]}
[0m09:39:34.242610 [info ] [Thread-1 (]: 1 of 7 OK created sql table model aemo.dim_calendar ............................ [[32mOK[0m in 4.02s]
[0m09:39:34.244717 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m09:39:34.245732 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m09:39:34.246515 [info ] [Thread-1 (]: 2 of 7 START sql table model aemo.dim_duid ..................................... [RUN]
[0m09:39:34.248322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m09:39:34.248322 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m09:39:34.248322 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m09:39:34.248322 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m09:39:34.264824 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_duid"
[0m09:39:34.267739 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:34.267739 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: BEGIN
[0m09:39:34.269247 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:39:34.272089 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m09:39:34.273488 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:34.274487 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_duid__dbt_tmp"
  
    as (
      

WITH
  states AS (
    SELECT 'WA1' AS RegionID, 'Western Australia' AS State
    UNION ALL SELECT 'QLD1', 'Queensland'
    UNION ALL SELECT 'NSW1', 'New South Wales'
    UNION ALL SELECT 'TAS1', 'Tasmania'
    UNION ALL SELECT 'SA1', 'South Australia'
    UNION ALL SELECT 'VIC1', 'Victoria'
  ),

  duid_aemo AS (
    SELECT
      DUID AS DUID,
      first(Region) AS Region,
      first("Fuel Source - Descriptor") AS FuelSourceDescriptor,
      first(Participant) AS Participant
    FROM
      read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
    WHERE
      length(DUID) > 2
    GROUP BY
      DUID
  ),

  wa_facilities AS (
    SELECT
      'WA1' AS Region,
      "Facility Code" AS DUID,
      "Participant Name" AS Participant
    FROM
      read_csv_auto('/lakehouse/default/Files/csv/duid/facilities.csv')
  ),

  wa_energy AS (
    SELECT *
    FROM read_csv_auto('/lakehouse/default/Files/csv/duid/WA_ENERGY.csv', header = 1)
  ),

  duid_wa AS (
    SELECT
      wa_facilities.DUID,
      wa_facilities.Region,
      wa_energy.Technology AS FuelSourceDescriptor,
      wa_facilities.Participant
    FROM wa_facilities
    LEFT JOIN wa_energy ON wa_facilities.DUID = wa_energy.DUID
  ),

  duid_all AS (
    SELECT * FROM duid_aemo
    UNION ALL
    SELECT * FROM duid_wa
  ),

  geo AS (
    SELECT
      duid,
      max(latitude) as latitude,
      max(longitude) as longitude
    FROM read_csv('/lakehouse/default/Files/csv/duid/geo_data.csv')
    WHERE latitude IS NOT NULL
    GROUP BY duid
  )

SELECT
  a.DUID,
  a.Region,
  UPPER(LEFT(TRIM(FuelSourceDescriptor), 1)) || LOWER(SUBSTR(TRIM(FuelSourceDescriptor), 2)) AS FuelSourceDescriptor,
  a.Participant,
  states.State,
  geo.latitude,
  geo.longitude
FROM duid_all a
JOIN states ON a.Region = states.RegionID
LEFT JOIN geo ON a.duid = geo.duid
    );
  
  
[0m09:39:38.705225 [debug] [Thread-1 (]: SQL status: OK in 4.434 seconds
[0m09:39:38.705225 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.705225 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

    SELECT index_name
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_duid'
  
[0m09:39:38.724172 [debug] [Thread-1 (]: SQL status: OK in 0.007 seconds
[0m09:39:38.728065 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.729368 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

    SELECT COUNT(*) as remaining_indexes
    FROM duckdb_indexes()
    WHERE schema_name = 'aemo'
      AND table_name = 'dim_duid'
  
[0m09:39:38.730370 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:38.730370 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.730370 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */
alter table "ducklake"."aemo"."dim_duid" rename to "dim_duid__dbt_backup"
[0m09:39:38.730370 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:39:38.742342 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.743339 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */
alter table "ducklake"."aemo"."dim_duid__dbt_tmp" rename to "dim_duid"
[0m09:39:38.744580 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:39:38.745584 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:39:38.745584 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.746606 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:39:38.766347 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m09:39:38.766347 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:39:38.766347 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

      drop table if exists "ducklake"."aemo"."dim_duid__dbt_backup"
    
[0m09:39:38.805637 [debug] [Thread-1 (]: SQL status: OK in 0.045 seconds
[0m09:39:38.805637 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: Close
[0m09:39:38.805637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000274895FD410>]}
[0m09:39:38.805637 [info ] [Thread-1 (]: 2 of 7 OK created sql table model aemo.dim_duid ................................ [[32mOK[0m in 4.56s]
[0m09:39:38.821434 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m09:39:38.821434 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m09:39:38.821434 [info ] [Thread-1 (]: 3 of 7 START sql incremental model aemo.fct_price .............................. [RUN]
[0m09:39:38.821434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m09:39:38.821434 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m09:39:38.821434 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m09:39:38.821434 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m09:39:38.868026 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price"
[0m09:39:38.868026 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:39:38.868026 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: BEGIN
[0m09:39:38.874481 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:39:38.875488 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:38.877835 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:39:38.877835 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:39:38.916723 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:39:38.916723 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:39:38.916723 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: ROLLBACK
[0m09:39:38.933810 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price'
[0m09:39:38.933810 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: Close
[0m09:39:38.933810 [debug] [Thread-1 (]: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:38.933810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487C5AF50>]}
[0m09:39:38.933810 [error] [Thread-1 (]: 3 of 7 ERROR creating sql incremental model aemo.fct_price ..................... [[31mERROR[0m in 0.11s]
[0m09:39:38.941150 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m09:39:38.942021 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m09:39:38.942021 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:39:38.942021 [info ] [Thread-1 (]: 4 of 7 START sql incremental model aemo.fct_price_today ........................ [RUN]
[0m09:39:38.942021 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m09:39:38.942021 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m09:39:38.951677 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m09:39:38.953827 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m09:39:38.957833 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price_today"
[0m09:39:38.959840 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:39:38.960877 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: BEGIN
[0m09:39:38.961851 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:39:38.963438 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:38.964444 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:39:38.965556 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:39:38.974442 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:39:38.975373 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:39:38.975373 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: ROLLBACK
[0m09:39:38.978046 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price_today'
[0m09:39:38.978046 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: Close
[0m09:39:38.985749 [debug] [Thread-1 (]: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:38.985749 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487F2E090>]}
[0m09:39:38.986753 [error] [Thread-1 (]: 4 of 7 ERROR creating sql incremental model aemo.fct_price_today ............... [[31mERROR[0m in 0.04s]
[0m09:39:38.989245 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m09:39:38.990124 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m09:39:38.990124 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:39:38.991548 [info ] [Thread-1 (]: 5 of 7 START sql incremental model aemo.fct_scada .............................. [RUN]
[0m09:39:38.992615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m09:39:38.993705 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m09:39:38.999673 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m09:39:38.999673 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m09:39:39.008448 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada"
[0m09:39:39.011010 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:39:39.012051 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: BEGIN
[0m09:39:39.013521 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:39:39.014569 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:39.015584 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:39:39.016582 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:39:39.025543 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:39:39.025543 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:39:39.025543 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: ROLLBACK
[0m09:39:39.025543 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada'
[0m09:39:39.025543 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: Close
[0m09:39:39.036956 [debug] [Thread-1 (]: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.037957 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002748950D510>]}
[0m09:39:39.039963 [error] [Thread-1 (]: 5 of 7 ERROR creating sql incremental model aemo.fct_scada ..................... [[31mERROR[0m in 0.05s]
[0m09:39:39.041372 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m09:39:39.042523 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m09:39:39.043506 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:39:39.045438 [info ] [Thread-1 (]: 6 of 7 START sql incremental model aemo.fct_scada_today ........................ [RUN]
[0m09:39:39.047424 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m09:39:39.048496 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m09:39:39.053125 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m09:39:39.053125 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m09:39:39.061331 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada_today"
[0m09:39:39.063339 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:39:39.064372 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: BEGIN
[0m09:39:39.065339 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:39:39.067254 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:39:39.067254 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:39:39.068255 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:39:39.075831 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:39:39.075831 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:39:39.078345 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: ROLLBACK
[0m09:39:39.078345 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada_today'
[0m09:39:39.078345 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: Close
[0m09:39:39.085945 [debug] [Thread-1 (]: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.085945 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cf082c1-67c3-433b-a02c-3f73efb055b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000274895AAF10>]}
[0m09:39:39.086892 [error] [Thread-1 (]: 6 of 7 ERROR creating sql incremental model aemo.fct_scada_today ............... [[31mERROR[0m in 0.04s]
[0m09:39:39.088751 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m09:39:39.088751 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m09:39:39.089758 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:39:39.090758 [info ] [Thread-1 (]: 7 of 7 SKIP relation aemo.fct_summary .......................................... [[33mSKIP[0m]
[0m09:39:39.091451 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m09:39:39.094137 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:39.094137 [debug] [MainThread]: On master: BEGIN
[0m09:39:39.095137 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:39:39.096140 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:39:39.097234 [debug] [MainThread]: On master: COMMIT
[0m09:39:39.097234 [debug] [MainThread]: Using duckdb connection "master"
[0m09:39:39.098138 [debug] [MainThread]: On master: COMMIT
[0m09:39:39.098138 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:39:39.099137 [debug] [MainThread]: On master: Close
[0m09:39:39.099137 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:39:39.100137 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:39:39.100137 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:39:39.100137 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_scada_today' was properly closed.
[0m09:39:39.100137 [info ] [MainThread]: 
[0m09:39:39.100137 [info ] [MainThread]: Finished running 5 incremental models, 1 project hook, 2 table models in 0 hours 0 minutes and 57.55 seconds (57.55s).
[0m09:39:39.105859 [debug] [MainThread]: Command end result
[0m09:39:39.135033 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:39:39.141485 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:39:39.148354 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\lakehouse\default\Files\dbt\target\run_results.json
[0m09:39:39.149678 [info ] [MainThread]: 
[0m09:39:39.150254 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m09:39:39.151301 [info ] [MainThread]: 
[0m09:39:39.152301 [error] [MainThread]: [31mFailure in model fct_price (models\marts\fct_price.sql)[0m
[0m09:39:39.153308 [error] [MainThread]:   Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.155328 [info ] [MainThread]: 
[0m09:39:39.155328 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price.sql
[0m09:39:39.157187 [info ] [MainThread]: 
[0m09:39:39.158252 [error] [MainThread]: [31mFailure in model fct_price_today (models\marts\fct_price_today.sql)[0m
[0m09:39:39.159274 [error] [MainThread]:   Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.160283 [info ] [MainThread]: 
[0m09:39:39.161281 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price_today.sql
[0m09:39:39.162282 [info ] [MainThread]: 
[0m09:39:39.163281 [error] [MainThread]: [31mFailure in model fct_scada (models\marts\fct_scada.sql)[0m
[0m09:39:39.164282 [error] [MainThread]:   Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.165283 [info ] [MainThread]: 
[0m09:39:39.166418 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada.sql
[0m09:39:39.166418 [info ] [MainThread]: 
[0m09:39:39.168425 [error] [MainThread]: [31mFailure in model fct_scada_today (models\marts\fct_scada_today.sql)[0m
[0m09:39:39.169423 [error] [MainThread]:   Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:39:39.170419 [info ] [MainThread]: 
[0m09:39:39.171070 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada_today.sql
[0m09:39:39.172887 [info ] [MainThread]: 
[0m09:39:39.173896 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=4 SKIP=1 NO-OP=0 TOTAL=8
[0m09:39:39.174854 [debug] [MainThread]: Command `dbt run` failed at 09:39:39.174854 after 59.09 seconds
[0m09:39:39.174854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027481830050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027487687D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027481662910>]}
[0m09:39:39.174854 [debug] [MainThread]: Flushing usage events
[0m09:39:40.438581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:42:27.712186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3C90B650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC386FE410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3C90BC10>]}


============================== 09:42:27.728074 | fe2f4460-c811-43c3-a54a-8b6a00401f7a ==============================
[0m09:42:27.728074 [info ] [MainThread]: Running with dbt=1.11.2
[0m09:42:27.728074 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'empty': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'profiles_dir': 'C:\\lakehouse\\default\\Files\\dbt', 'quiet': 'False', 'log_format': 'default', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'log_path': 'C:\\lakehouse\\default\\Files\\dbt\\logs', 'introspect': 'True', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'target_path': 'None'}
[0m09:42:28.163333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3CB97F10>]}
[0m09:42:28.227004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC383F83D0>]}
[0m09:42:28.227004 [info ] [MainThread]: Registered adapter: duckdb=1.10.0
[0m09:42:28.728555 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m09:42:28.808660 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:42:28.808660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3CC296D0>]}
[0m09:42:30.112045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3CEF9750>]}
[0m09:42:30.185455 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:42:30.203290 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:42:30.249173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E240550>]}
[0m09:42:30.249173 [info ] [MainThread]: Found 7 models, 1 operation, 1 source, 474 macros
[0m09:42:30.262412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3CBB2E90>]}
[0m09:42:30.265043 [info ] [MainThread]: 
[0m09:42:30.267055 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:42:30.267055 [info ] [MainThread]: 
[0m09:42:30.269066 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m09:42:30.277099 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake'
[0m09:42:30.678588 [debug] [ThreadPool]: Using duckdb connection "list_ducklake"
[0m09:42:30.678588 [debug] [ThreadPool]: On list_ducklake: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"ducklake"'
    
  
  
[0m09:42:30.678588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:42:31.114664 [debug] [ThreadPool]: SQL status: OK in 0.429 seconds
[0m09:42:31.116676 [debug] [ThreadPool]: On list_ducklake: Close
[0m09:42:31.116676 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_ducklake, now create_ducklake_aemo)
[0m09:42:31.118583 [debug] [ThreadPool]: Creating schema "database: "ducklake"
schema: "aemo"
"
[0m09:42:31.125616 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:42:31.125616 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
        select type from duckdb_databases()
        where lower(database_name)='ducklake'
        and type='sqlite'
    
  
[0m09:42:31.125616 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:42:31.127624 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m09:42:31.127624 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:42:31.127624 [debug] [ThreadPool]: On create_ducklake_aemo: BEGIN
[0m09:42:31.131222 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:42:31.131222 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:42:31.131222 [debug] [ThreadPool]: On create_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "create_ducklake_aemo"} */

    
    
        create schema if not exists "ducklake"."aemo"
    
[0m09:42:31.136124 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m09:42:31.136124 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:42:31.136124 [debug] [ThreadPool]: Using duckdb connection "create_ducklake_aemo"
[0m09:42:31.136124 [debug] [ThreadPool]: On create_ducklake_aemo: COMMIT
[0m09:42:31.136124 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m09:42:31.136124 [debug] [ThreadPool]: On create_ducklake_aemo: Close
[0m09:42:31.136124 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_ducklake_aemo'
[0m09:42:31.152091 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:42:31.152091 [debug] [ThreadPool]: On list_ducklake_aemo: BEGIN
[0m09:42:31.152091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:42:31.152091 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m09:42:31.152091 [debug] [ThreadPool]: Using duckdb connection "list_ducklake_aemo"
[0m09:42:31.152091 [debug] [ThreadPool]: On list_ducklake_aemo: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "list_ducklake_aemo"} */
select
      'ducklake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'aemo'
    and lower(table_catalog) = 'ducklake'
  
[0m09:42:31.198777 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m09:42:31.199783 [debug] [ThreadPool]: On list_ducklake_aemo: ROLLBACK
[0m09:42:31.201809 [debug] [ThreadPool]: Failed to rollback 'list_ducklake_aemo'
[0m09:42:31.202782 [debug] [ThreadPool]: On list_ducklake_aemo: Close
[0m09:42:31.203781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E2ADB50>]}
[0m09:42:31.203781 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.203781 [debug] [MainThread]: On master: BEGIN
[0m09:42:31.203781 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:42:31.203781 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.203781 [debug] [MainThread]: On master: COMMIT
[0m09:42:31.203781 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.203781 [debug] [MainThread]: On master: COMMIT
[0m09:42:31.203781 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:42:31.214264 [info ] [MainThread]: [DOWNLOAD] Starting download with PATH_ROOT=/lakehouse/default, download_limit=2
[0m09:42:31.214264 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.219812 [debug] [MainThread]: On master: BEGIN
[0m09:42:31.219812 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.219812 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.219812 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE PATH_ROOT = '/lakehouse/default'

[0m09:42:31.219812 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.219812 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.219812 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE download_limit = 2

[0m09:42:31.219812 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.219812 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.235938 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE csv_archive_path = getvariable('PATH_ROOT') || '/Files/csv'

[0m09:42:31.237220 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.239703 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.240736 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE SCHEMA IF NOT EXISTS ducklake.aemo

[0m09:42:31.271277 [debug] [MainThread]: SQL status: OK in 0.030 seconds
[0m09:42:31.273277 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.274277 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

USE ducklake.aemo

[0m09:42:31.274277 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:42:31.276330 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.278335 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE TABLE IF NOT EXISTS aemo.csv_archive_log (
  source_type VARCHAR,
  source_filename VARCHAR,
  archive_path VARCHAR,
  archived_at TIMESTAMP,
  row_count BIGINT,
  source_url VARCHAR,
  etag VARCHAR
)

[0m09:42:31.278335 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.281426 [info ] [MainThread]: [DOWNLOAD] Daily source: aemo
[0m09:42:31.281426 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.281426 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_files_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('https://nemweb.com.au/Reports/Current/Daily_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'https://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DAILY%.zip%'
ORDER BY full_url DESC

[0m09:42:31.459245 [debug] [MainThread]: SQL status: OK in 0.177 seconds
[0m09:42:31.459245 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.459245 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE daily_to_archive AS
SELECT full_url, filename
FROM daily_files_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'daily')
LIMIT getvariable('download_limit')

[0m09:42:31.459245 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:42:31.459245 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.459245 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_daily_to_archive = (SELECT count(*) > 0 FROM daily_to_archive)

[0m09:42:31.459245 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.459245 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.459245 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM daily_to_archive)

[0m09:42:31.459245 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:42:31.474997 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.474997 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_expected = (SELECT count(*) FROM daily_to_archive)

[0m09:42:31.474997 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:31.474997 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.474997 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE daily_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM daily_to_archive)

[0m09:42:31.474997 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:42:31.474997 [info ] [MainThread]: [DOWNLOAD] Processing daily files...
[0m09:42:31.474997 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:31.474997 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    CAST(substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 4) AS INT) AS year
  FROM read_blob(getvariable('daily_urls'))
  WHERE getvariable('has_daily_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/daily')
(FORMAT BLOB, PARTITION_BY (year, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:42:32.127882 [debug] [MainThread]: SQL status: OK in 0.641 seconds
[0m09:42:32.131906 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:32.133916 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'daily' AS source_type,
  filename AS source_filename,
  '/daily/year=' || CAST(substring(split_part(filename, '_', 3), 1, 4) AS INT) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM daily_to_archive
WHERE getvariable('daily_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('daily_paths'))) = getvariable('daily_expected')

[0m09:42:42.198615 [debug] [MainThread]: SQL status: OK in 10.075 seconds
[0m09:42:42.213077 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:42.214589 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_scada_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/Dispatch_SCADA/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHSCADA%'
ORDER BY full_url DESC
LIMIT 500

[0m09:42:42.392825 [debug] [MainThread]: SQL status: OK in 0.180 seconds
[0m09:42:42.392825 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:42.392825 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE scada_today_to_archive AS
SELECT full_url, filename
FROM intraday_scada_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'scada_today')
LIMIT getvariable('download_limit')

[0m09:42:45.351621 [debug] [MainThread]: SQL status: OK in 2.952 seconds
[0m09:42:45.351621 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.351621 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_scada_today_to_archive = (SELECT count(*) > 0 FROM scada_today_to_archive)

[0m09:42:45.351621 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:42:45.367301 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.369316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM scada_today_to_archive)

[0m09:42:45.373598 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m09:42:45.373598 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.383064 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_expected = (SELECT count(*) FROM scada_today_to_archive)

[0m09:42:45.383064 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:42:45.388221 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.390238 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE scada_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM scada_today_to_archive)

[0m09:42:45.398968 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m09:42:45.398968 [info ] [MainThread]: [DOWNLOAD] Processing intraday SCADA files...
[0m09:42:45.398968 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.398968 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('scada_urls'))
  WHERE getvariable('has_scada_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/scada_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:42:45.522187 [debug] [MainThread]: SQL status: OK in 0.130 seconds
[0m09:42:45.537895 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:45.544019 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'scada_today' AS source_type,
  filename AS source_filename,
  '/scada_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM scada_today_to_archive
WHERE getvariable('scada_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('scada_paths'))) = getvariable('scada_expected')

[0m09:42:50.412663 [debug] [MainThread]: SQL status: OK in 4.869 seconds
[0m09:42:50.412663 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:50.412663 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE intraday_price_web AS
WITH
  html_data AS (
    SELECT content AS html FROM read_text('http://nemweb.com.au/Reports/Current/DispatchIS_Reports/')
  ),
  lines AS (
    SELECT unnest(string_split(html, '<br>')) AS line FROM html_data
  )
SELECT
  'http://nemweb.com.au' || regexp_extract(line, 'HREF="([^"]+)"', 1) AS full_url,
  split_part(regexp_extract(line, 'HREF="[^"]+/([^"]+\.zip)"', 1), '.', 1) AS filename
FROM lines
WHERE line LIKE '%PUBLIC_DISPATCHIS_%.zip%'
ORDER BY full_url DESC
LIMIT 500

[0m09:42:50.612055 [debug] [MainThread]: SQL status: OK in 0.198 seconds
[0m09:42:50.612055 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:50.612055 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

CREATE OR REPLACE TEMP TABLE price_today_to_archive AS
SELECT full_url, filename
FROM intraday_price_web
WHERE filename NOT IN (SELECT source_filename FROM csv_archive_log WHERE source_type = 'price_today')
LIMIT getvariable('download_limit')

[0m09:42:52.917526 [debug] [MainThread]: SQL status: OK in 2.296 seconds
[0m09:42:52.919534 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:52.921546 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE has_price_today_to_archive = (SELECT count(*) > 0 FROM price_today_to_archive)

[0m09:42:52.923576 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:52.925090 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:52.926090 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_urls = (SELECT COALESCE(NULLIF(list(full_url), []), list_value('')) FROM price_today_to_archive)

[0m09:42:52.930157 [debug] [MainThread]: SQL status: OK in 0.003 seconds
[0m09:42:52.930770 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:52.930770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_expected = (SELECT count(*) FROM price_today_to_archive)

[0m09:42:52.932776 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:42:52.935693 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:52.935693 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

SET VARIABLE price_paths = (SELECT COALESCE(NULLIF(list(getvariable('csv_archive_path') || '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip'), []), list_value('')) FROM price_today_to_archive)

[0m09:42:52.939703 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m09:42:52.941709 [info ] [MainThread]: [DOWNLOAD] Processing intraday PRICE files...
[0m09:42:52.943713 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:52.943713 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT
    content,
    split_part(split_part(filename, '/', -1), '.', 1) AS source_file,
    substring(split_part(split_part(filename, '/', -1), '_', 3), 1, 8) AS day
  FROM read_blob(getvariable('price_urls'))
  WHERE getvariable('has_price_today_to_archive') AND filename != ''
) TO (getvariable('csv_archive_path') || '/price_today')
(FORMAT BLOB, PARTITION_BY (day, source_file), FILE_EXTENSION 'zip', OVERWRITE_OR_IGNORE)

[0m09:42:53.123536 [debug] [MainThread]: SQL status: OK in 0.185 seconds
[0m09:42:53.133882 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:53.133882 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT
  'price_today' AS source_type,
  filename AS source_filename,
  '/price_today/day=' || substring(split_part(filename, '_', 3), 1, 8) || '/source_file=' || filename || '/data_0.zip' AS archive_path,
  now() AS archived_at
FROM price_today_to_archive
WHERE getvariable('price_expected') > 0
  AND (SELECT count(*) FROM glob(getvariable('price_paths'))) = getvariable('price_expected')

[0m09:42:59.072050 [debug] [MainThread]: SQL status: OK in 5.935 seconds
[0m09:42:59.072050 [info ] [MainThread]: [DOWNLOAD] Refreshing 4 DUID reference files...
[0m09:42:59.072050 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.072050 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (SELECT 1 AS id, 'init' AS dummy) TO (getvariable('csv_archive_path') || '/duid')
(FORMAT csv, PARTITION_BY (dummy), FILE_EXTENSION 'csv', OVERWRITE_OR_IGNORE)

[0m09:42:59.072050 [debug] [MainThread]: SQL status: OK in 0.002 seconds
[0m09:42:59.072050 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.072050 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/djouallah-patch-1/duid_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/duid_data.csv') (FORMAT CSV, HEADER)

[0m09:42:59.120808 [debug] [MainThread]: SQL status: OK in 0.046 seconds
[0m09:42:59.128678 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.128678 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://data.wa.aemo.com.au/datafiles/post-facilities/facilities.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/facilities.csv') (FORMAT CSV, HEADER)

[0m09:42:59.425872 [debug] [MainThread]: SQL status: OK in 0.295 seconds
[0m09:42:59.429409 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.431422 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/WA_ENERGY.csv', header=true, null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/WA_ENERGY.csv') (FORMAT CSV, HEADER)

[0m09:42:59.478140 [debug] [MainThread]: SQL status: OK in 0.051 seconds
[0m09:42:59.478140 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.478140 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

COPY (
  SELECT * FROM read_csv_auto('https://raw.githubusercontent.com/djouallah/aemo_fabric/refs/heads/main/geo_data.csv', null_padding=true, ignore_errors=true)
) TO (getvariable('csv_archive_path') || '/duid/geo_data.csv') (FORMAT CSV, HEADER)

[0m09:42:59.547822 [debug] [MainThread]: SQL status: OK in 0.059 seconds
[0m09:42:59.551849 [debug] [MainThread]: Using duckdb connection "master"
[0m09:42:59.552861 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

DELETE FROM csv_archive_log WHERE source_type LIKE 'duid_%'

[0m09:43:01.791307 [debug] [MainThread]: SQL status: OK in 2.239 seconds
[0m09:43:01.794518 [debug] [MainThread]: Using duckdb connection "master"
[0m09:43:01.796523 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "connection_name": "master"} */

INSERT INTO csv_archive_log BY NAME
SELECT * FROM (VALUES
  ('duid_data', 'duid_data', '/duid/duid_data.csv', now()),
  ('duid_facilities', 'facilities', '/duid/facilities.csv', now()),
  ('duid_wa_energy', 'WA_ENERGY', '/duid/WA_ENERGY.csv', now()),
  ('duid_geo_data', 'geo_data', '/duid/geo_data.csv', now())
) AS t(source_type, source_filename, archive_path, archived_at)

[0m09:43:07.735509 [debug] [MainThread]: SQL status: OK in 5.948 seconds
[0m09:43:07.749131 [info ] [MainThread]: [DOWNLOAD] DUID files written: 4
[0m09:43:07.751644 [info ] [MainThread]: [DOWNLOAD COMPLETE]
[0m09:43:07.752811 [debug] [MainThread]: Writing injected SQL for node "operation.aemo_electricity.aemo_electricity-on-run-start-0"
[0m09:43:07.769079 [info ] [MainThread]: 1 of 1 START hook: aemo_electricity.on-run-start.0 ............................. [RUN]
[0m09:43:07.771819 [info ] [MainThread]: 1 of 1 OK hook: aemo_electricity.on-run-start.0 ................................ [[32mOK[0m in 36.57s]
[0m09:43:07.774053 [info ] [MainThread]: 
[0m09:43:07.776046 [debug] [MainThread]: On master: ROLLBACK
[0m09:43:07.782714 [debug] [MainThread]: Failed to rollback 'master'
[0m09:43:07.784721 [debug] [MainThread]: On master: Close
[0m09:43:18.534590 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_calendar
[0m09:43:18.534590 [info ] [Thread-1 (]: 1 of 7 START sql table model aemo.dim_calendar ................................. [RUN]
[0m09:43:18.534590 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.aemo_electricity.dim_calendar'
[0m09:43:18.534590 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_calendar
[0m09:43:18.553135 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_calendar"
[0m09:43:18.558181 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_calendar
[0m09:43:18.652640 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_calendar"
[0m09:43:18.656413 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:43:18.656413 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: BEGIN
[0m09:43:18.656413 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:43:18.656413 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m09:43:18.656413 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:43:18.656413 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_calendar__dbt_tmp"
  
    as (
      

SELECT
  CAST(date AS DATE) as date,
  CAST(EXTRACT(year FROM date) AS INT) as year,
  CAST(EXTRACT(month FROM date) AS INT) as month
FROM (
  SELECT unnest(generate_series(
    CAST('2018-04-01' AS DATE),
    CAST('2026-12-31' AS DATE),
    INTERVAL 1 DAY
  )) as date
)
    );
  
  
[0m09:43:23.240686 [debug] [Thread-1 (]: SQL status: OK in 4.572 seconds
[0m09:43:23.256513 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:43:23.256513 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */
alter table "ducklake"."aemo"."dim_calendar__dbt_tmp" rename to "dim_calendar"
[0m09:43:23.256513 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:43:23.272495 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:43:23.272495 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:43:23.272495 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: COMMIT
[0m09:43:23.312089 [debug] [Thread-1 (]: SQL status: OK in 0.029 seconds
[0m09:43:23.323913 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_calendar"
[0m09:43:23.325924 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_calendar"} */

      drop table if exists "ducklake"."aemo"."dim_calendar__dbt_backup"
    
[0m09:43:23.370108 [debug] [Thread-1 (]: SQL status: OK in 0.050 seconds
[0m09:43:23.370108 [debug] [Thread-1 (]: On model.aemo_electricity.dim_calendar: Close
[0m09:43:23.370108 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E7D6250>]}
[0m09:43:23.383272 [info ] [Thread-1 (]: 1 of 7 OK created sql table model aemo.dim_calendar ............................ [[32mOK[0m in 4.84s]
[0m09:43:23.383272 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_calendar
[0m09:43:23.383272 [debug] [Thread-1 (]: Began running node model.aemo_electricity.dim_duid
[0m09:43:23.383272 [info ] [Thread-1 (]: 2 of 7 START sql table model aemo.dim_duid ..................................... [RUN]
[0m09:43:23.383272 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_calendar, now model.aemo_electricity.dim_duid)
[0m09:43:23.383272 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.dim_duid
[0m09:43:23.383272 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.dim_duid"
[0m09:43:23.383272 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.dim_duid
[0m09:43:23.383272 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.dim_duid"
[0m09:43:23.383272 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:43:23.383272 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: BEGIN
[0m09:43:23.383272 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:23.398957 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:43:23.399840 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:43:23.400847 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

  
    
    

    create  table
      "ducklake"."aemo"."dim_duid__dbt_tmp"
  
    as (
      

WITH
  states AS (
    SELECT 'WA1' AS RegionID, 'Western Australia' AS State
    UNION ALL SELECT 'QLD1', 'Queensland'
    UNION ALL SELECT 'NSW1', 'New South Wales'
    UNION ALL SELECT 'TAS1', 'Tasmania'
    UNION ALL SELECT 'SA1', 'South Australia'
    UNION ALL SELECT 'VIC1', 'Victoria'
  ),

  duid_aemo AS (
    SELECT
      DUID AS DUID,
      first(Region) AS Region,
      first("Fuel Source - Descriptor") AS FuelSourceDescriptor,
      first(Participant) AS Participant
    FROM
      read_csv('/lakehouse/default/Files/csv/duid/duid_data.csv')
    WHERE
      length(DUID) > 2
    GROUP BY
      DUID
  ),

  wa_facilities AS (
    SELECT
      'WA1' AS Region,
      "Facility Code" AS DUID,
      "Participant Name" AS Participant
    FROM
      read_csv_auto('/lakehouse/default/Files/csv/duid/facilities.csv')
  ),

  wa_energy AS (
    SELECT *
    FROM read_csv_auto('/lakehouse/default/Files/csv/duid/WA_ENERGY.csv', header = 1)
  ),

  duid_wa AS (
    SELECT
      wa_facilities.DUID,
      wa_facilities.Region,
      wa_energy.Technology AS FuelSourceDescriptor,
      wa_facilities.Participant
    FROM wa_facilities
    LEFT JOIN wa_energy ON wa_facilities.DUID = wa_energy.DUID
  ),

  duid_all AS (
    SELECT * FROM duid_aemo
    UNION ALL
    SELECT * FROM duid_wa
  ),

  geo AS (
    SELECT
      duid,
      max(latitude) as latitude,
      max(longitude) as longitude
    FROM read_csv('/lakehouse/default/Files/csv/duid/geo_data.csv')
    WHERE latitude IS NOT NULL
    GROUP BY duid
  )

SELECT
  a.DUID,
  a.Region,
  UPPER(LEFT(TRIM(FuelSourceDescriptor), 1)) || LOWER(SUBSTR(TRIM(FuelSourceDescriptor), 2)) AS FuelSourceDescriptor,
  a.Participant,
  states.State,
  geo.latitude,
  geo.longitude
FROM duid_all a
JOIN states ON a.Region = states.RegionID
LEFT JOIN geo ON a.duid = geo.duid
    );
  
  
[0m09:43:27.434984 [debug] [Thread-1 (]: SQL status: OK in 4.044 seconds
[0m09:43:27.450154 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:43:27.450154 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */
alter table "ducklake"."aemo"."dim_duid__dbt_tmp" rename to "dim_duid"
[0m09:43:27.450154 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:43:27.450154 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:43:27.450154 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:43:27.450154 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: COMMIT
[0m09:43:27.495692 [debug] [Thread-1 (]: SQL status: OK in 0.030 seconds
[0m09:43:27.498793 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.dim_duid"
[0m09:43:27.498793 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.dim_duid"} */

      drop table if exists "ducklake"."aemo"."dim_duid__dbt_backup"
    
[0m09:43:27.535537 [debug] [Thread-1 (]: SQL status: OK in 0.036 seconds
[0m09:43:27.538091 [debug] [Thread-1 (]: On model.aemo_electricity.dim_duid: Close
[0m09:43:27.539088 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E29C9D0>]}
[0m09:43:27.539088 [info ] [Thread-1 (]: 2 of 7 OK created sql table model aemo.dim_duid ................................ [[32mOK[0m in 4.15s]
[0m09:43:27.540317 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.dim_duid
[0m09:43:27.541322 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price
[0m09:43:27.541322 [info ] [Thread-1 (]: 3 of 7 START sql incremental model aemo.fct_price .............................. [RUN]
[0m09:43:27.542642 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.dim_duid, now model.aemo_electricity.fct_price)
[0m09:43:27.543687 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price
[0m09:43:27.545448 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price"
[0m09:43:27.545448 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price
[0m09:43:27.591303 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price"
[0m09:43:27.593314 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:43:27.594301 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: BEGIN
[0m09:43:27.595300 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:27.597307 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m09:43:27.597307 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price"
[0m09:43:27.599307 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:43:27.610481 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'TOTALDEMAND': 'VARCHAR',
      'DEMANDFORECAST': 'VARCHAR',
      'DISPATCHABLEGENERATION': 'VARCHAR',
      'DISPATCHABLELOAD': 'VARCHAR',
      'NETINTERCHANGE': 'VARCHAR',
      'EXCESSGENERATION': 'VARCHAR',
      'LOWER5MINDISPATCH': 'VARCHAR',
      'LOWER5MINIMPORT': 'VARCHAR',
      'LOWER5MINLOCALDISPATCH': 'VARCHAR',
      'LOWER5MINLOCALPRICE': 'VARCHAR',
      'LOWER5MINLOCALREQ': 'VARCHAR',
      'LOWER5MINPRICE': 'VARCHAR',
      'LOWER5MINREQ': 'VARCHAR',
      'LOWER5MINSUPPLYPRICE': 'VARCHAR',
      'LOWER60SECDISPATCH': 'VARCHAR',
      'LOWER60SECIMPORT': 'VARCHAR',
      'LOWER60SECLOCALDISPATCH': 'VARCHAR',
      'LOWER60SECLOCALPRICE': 'VARCHAR',
      'LOWER60SECLOCALREQ': 'VARCHAR',
      'LOWER60SECPRICE': 'VARCHAR',
      'LOWER60SECREQ': 'VARCHAR',
      'LOWER60SECSUPPLYPRICE': 'VARCHAR',
      'LOWER6SECDISPATCH': 'VARCHAR',
      'LOWER6SECIMPORT': 'VARCHAR',
      'LOWER6SECLOCALDISPATCH': 'VARCHAR',
      'LOWER6SECLOCALPRICE': 'VARCHAR',
      'LOWER6SECLOCALREQ': 'VARCHAR',
      'LOWER6SECPRICE': 'VARCHAR',
      'LOWER6SECREQ': 'VARCHAR',
      'LOWER6SECSUPPLYPRICE': 'VARCHAR',
      'RAISE5MINDISPATCH': 'VARCHAR',
      'RAISE5MINIMPORT': 'VARCHAR',
      'RAISE5MINLOCALDISPATCH': 'VARCHAR',
      'RAISE5MINLOCALPRICE': 'VARCHAR',
      'RAISE5MINLOCALREQ': 'VARCHAR',
      'RAISE5MINPRICE': 'VARCHAR',
      'RAISE5MINREQ': 'VARCHAR',
      'RAISE5MINSUPPLYPRICE': 'VARCHAR',
      'RAISE60SECDISPATCH': 'VARCHAR',
      'RAISE60SECIMPORT': 'VARCHAR',
      'RAISE60SECLOCALDISPATCH': 'VARCHAR',
      'RAISE60SECLOCALPRICE': 'VARCHAR',
      'RAISE60SECLOCALREQ': 'VARCHAR',
      'RAISE60SECPRICE': 'VARCHAR',
      'RAISE60SECREQ': 'VARCHAR',
      'RAISE60SECSUPPLYPRICE': 'VARCHAR',
      'RAISE6SECDISPATCH': 'VARCHAR',
      'RAISE6SECIMPORT': 'VARCHAR',
      'RAISE6SECLOCALDISPATCH': 'VARCHAR',
      'RAISE6SECLOCALPRICE': 'VARCHAR',
      'RAISE6SECLOCALREQ': 'VARCHAR',
      'RAISE6SECPRICE': 'VARCHAR',
      'RAISE6SECREQ': 'VARCHAR',
      'RAISE6SECSUPPLYPRICE': 'VARCHAR',
      'AGGREGATEDISPATCHERROR': 'VARCHAR',
      'AVAILABLEGENERATION': 'VARCHAR',
      'AVAILABLELOAD': 'VARCHAR',
      'INITIALSUPPLY': 'VARCHAR',
      'CLEAREDSUPPLY': 'VARCHAR',
      'LOWERREGIMPORT': 'VARCHAR',
      'LOWERREGLOCALDISPATCH': 'VARCHAR',
      'LOWERREGLOCALREQ': 'VARCHAR',
      'LOWERREGREQ': 'VARCHAR',
      'RAISEREGIMPORT': 'VARCHAR',
      'RAISEREGLOCALDISPATCH': 'VARCHAR',
      'RAISEREGLOCALREQ': 'VARCHAR',
      'RAISEREGREQ': 'VARCHAR',
      'RAISE5MINLOCALVIOLATION': 'VARCHAR',
      'RAISEREGLOCALVIOLATION': 'VARCHAR',
      'RAISE60SECLOCALVIOLATION': 'VARCHAR',
      'RAISE6SECLOCALVIOLATION': 'VARCHAR',
      'LOWER5MINLOCALVIOLATION': 'VARCHAR',
      'LOWERREGLOCALVIOLATION': 'VARCHAR',
      'LOWER60SECLOCALVIOLATION': 'VARCHAR',
      'LOWER6SECLOCALVIOLATION': 'VARCHAR',
      'RAISE5MINVIOLATION': 'VARCHAR',
      'RAISEREGVIOLATION': 'VARCHAR',
      'RAISE60SECVIOLATION': 'VARCHAR',
      'RAISE6SECVIOLATION': 'VARCHAR',
      'LOWER5MINVIOLATION': 'VARCHAR',
      'LOWERREGVIOLATION': 'VARCHAR',
      'LOWER60SECVIOLATION': 'VARCHAR',
      'LOWER6SECVIOLATION': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR',
      'LORSURPLUS': 'VARCHAR',
      'LRCSURPLUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DREGION' AND VERSION = '3'
)

SELECT
  UNIT,
  REGIONID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(TOTALDEMAND AS DOUBLE) AS TOTALDEMAND,
  CAST(DEMANDFORECAST AS DOUBLE) AS DEMANDFORECAST,
  CAST(DISPATCHABLEGENERATION AS DOUBLE) AS DISPATCHABLEGENERATION,
  CAST(DISPATCHABLELOAD AS DOUBLE) AS DISPATCHABLELOAD,
  CAST(NETINTERCHANGE AS DOUBLE) AS NETINTERCHANGE,
  CAST(EXCESSGENERATION AS DOUBLE) AS EXCESSGENERATION,
  CAST(LOWER5MINDISPATCH AS DOUBLE) AS LOWER5MINDISPATCH,
  CAST(LOWER5MINIMPORT AS DOUBLE) AS LOWER5MINIMPORT,
  CAST(LOWER5MINLOCALDISPATCH AS DOUBLE) AS LOWER5MINLOCALDISPATCH,
  CAST(LOWER5MINLOCALPRICE AS DOUBLE) AS LOWER5MINLOCALPRICE,
  CAST(LOWER5MINLOCALREQ AS DOUBLE) AS LOWER5MINLOCALREQ,
  CAST(LOWER5MINPRICE AS DOUBLE) AS LOWER5MINPRICE,
  CAST(LOWER5MINREQ AS DOUBLE) AS LOWER5MINREQ,
  CAST(LOWER5MINSUPPLYPRICE AS DOUBLE) AS LOWER5MINSUPPLYPRICE,
  CAST(LOWER60SECDISPATCH AS DOUBLE) AS LOWER60SECDISPATCH,
  CAST(LOWER60SECIMPORT AS DOUBLE) AS LOWER60SECIMPORT,
  CAST(LOWER60SECLOCALDISPATCH AS DOUBLE) AS LOWER60SECLOCALDISPATCH,
  CAST(LOWER60SECLOCALPRICE AS DOUBLE) AS LOWER60SECLOCALPRICE,
  CAST(LOWER60SECLOCALREQ AS DOUBLE) AS LOWER60SECLOCALREQ,
  CAST(LOWER60SECPRICE AS DOUBLE) AS LOWER60SECPRICE,
  CAST(LOWER60SECREQ AS DOUBLE) AS LOWER60SECREQ,
  CAST(LOWER60SECSUPPLYPRICE AS DOUBLE) AS LOWER60SECSUPPLYPRICE,
  CAST(LOWER6SECDISPATCH AS DOUBLE) AS LOWER6SECDISPATCH,
  CAST(LOWER6SECIMPORT AS DOUBLE) AS LOWER6SECIMPORT,
  CAST(LOWER6SECLOCALDISPATCH AS DOUBLE) AS LOWER6SECLOCALDISPATCH,
  CAST(LOWER6SECLOCALPRICE AS DOUBLE) AS LOWER6SECLOCALPRICE,
  CAST(LOWER6SECLOCALREQ AS DOUBLE) AS LOWER6SECLOCALREQ,
  CAST(LOWER6SECPRICE AS DOUBLE) AS LOWER6SECPRICE,
  CAST(LOWER6SECREQ AS DOUBLE) AS LOWER6SECREQ,
  CAST(LOWER6SECSUPPLYPRICE AS DOUBLE) AS LOWER6SECSUPPLYPRICE,
  CAST(RAISE5MINDISPATCH AS DOUBLE) AS RAISE5MINDISPATCH,
  CAST(RAISE5MINIMPORT AS DOUBLE) AS RAISE5MINIMPORT,
  CAST(RAISE5MINLOCALDISPATCH AS DOUBLE) AS RAISE5MINLOCALDISPATCH,
  CAST(RAISE5MINLOCALPRICE AS DOUBLE) AS RAISE5MINLOCALPRICE,
  CAST(RAISE5MINLOCALREQ AS DOUBLE) AS RAISE5MINLOCALREQ,
  CAST(RAISE5MINPRICE AS DOUBLE) AS RAISE5MINPRICE,
  CAST(RAISE5MINREQ AS DOUBLE) AS RAISE5MINREQ,
  CAST(RAISE5MINSUPPLYPRICE AS DOUBLE) AS RAISE5MINSUPPLYPRICE,
  CAST(RAISE60SECDISPATCH AS DOUBLE) AS RAISE60SECDISPATCH,
  CAST(RAISE60SECIMPORT AS DOUBLE) AS RAISE60SECIMPORT,
  CAST(RAISE60SECLOCALDISPATCH AS DOUBLE) AS RAISE60SECLOCALDISPATCH,
  CAST(RAISE60SECLOCALPRICE AS DOUBLE) AS RAISE60SECLOCALPRICE,
  CAST(RAISE60SECLOCALREQ AS DOUBLE) AS RAISE60SECLOCALREQ,
  CAST(RAISE60SECPRICE AS DOUBLE) AS RAISE60SECPRICE,
  CAST(RAISE60SECREQ AS DOUBLE) AS RAISE60SECREQ,
  CAST(RAISE60SECSUPPLYPRICE AS DOUBLE) AS RAISE60SECSUPPLYPRICE,
  CAST(RAISE6SECDISPATCH AS DOUBLE) AS RAISE6SECDISPATCH,
  CAST(RAISE6SECIMPORT AS DOUBLE) AS RAISE6SECIMPORT,
  CAST(RAISE6SECLOCALDISPATCH AS DOUBLE) AS RAISE6SECLOCALDISPATCH,
  CAST(RAISE6SECLOCALPRICE AS DOUBLE) AS RAISE6SECLOCALPRICE,
  CAST(RAISE6SECLOCALREQ AS DOUBLE) AS RAISE6SECLOCALREQ,
  CAST(RAISE6SECPRICE AS DOUBLE) AS RAISE6SECPRICE,
  CAST(RAISE6SECREQ AS DOUBLE) AS RAISE6SECREQ,
  CAST(RAISE6SECSUPPLYPRICE AS DOUBLE) AS RAISE6SECSUPPLYPRICE,
  CAST(AGGREGATEDISPATCHERROR AS DOUBLE) AS AGGREGATEDISPATCHERROR,
  CAST(AVAILABLEGENERATION AS DOUBLE) AS AVAILABLEGENERATION,
  CAST(AVAILABLELOAD AS DOUBLE) AS AVAILABLELOAD,
  CAST(INITIALSUPPLY AS DOUBLE) AS INITIALSUPPLY,
  CAST(CLEAREDSUPPLY AS DOUBLE) AS CLEAREDSUPPLY,
  CAST(LOWERREGIMPORT AS DOUBLE) AS LOWERREGIMPORT,
  CAST(LOWERREGLOCALDISPATCH AS DOUBLE) AS LOWERREGLOCALDISPATCH,
  CAST(LOWERREGLOCALREQ AS DOUBLE) AS LOWERREGLOCALREQ,
  CAST(LOWERREGREQ AS DOUBLE) AS LOWERREGREQ,
  CAST(RAISEREGIMPORT AS DOUBLE) AS RAISEREGIMPORT,
  CAST(RAISEREGLOCALDISPATCH AS DOUBLE) AS RAISEREGLOCALDISPATCH,
  CAST(RAISEREGLOCALREQ AS DOUBLE) AS RAISEREGLOCALREQ,
  CAST(RAISEREGREQ AS DOUBLE) AS RAISEREGREQ,
  CAST(RAISE5MINLOCALVIOLATION AS DOUBLE) AS RAISE5MINLOCALVIOLATION,
  CAST(RAISEREGLOCALVIOLATION AS DOUBLE) AS RAISEREGLOCALVIOLATION,
  CAST(RAISE60SECLOCALVIOLATION AS DOUBLE) AS RAISE60SECLOCALVIOLATION,
  CAST(RAISE6SECLOCALVIOLATION AS DOUBLE) AS RAISE6SECLOCALVIOLATION,
  CAST(LOWER5MINLOCALVIOLATION AS DOUBLE) AS LOWER5MINLOCALVIOLATION,
  CAST(LOWERREGLOCALVIOLATION AS DOUBLE) AS LOWERREGLOCALVIOLATION,
  CAST(LOWER60SECLOCALVIOLATION AS DOUBLE) AS LOWER60SECLOCALVIOLATION,
  CAST(LOWER6SECLOCALVIOLATION AS DOUBLE) AS LOWER6SECLOCALVIOLATION,
  CAST(RAISE5MINVIOLATION AS DOUBLE) AS RAISE5MINVIOLATION,
  CAST(RAISEREGVIOLATION AS DOUBLE) AS RAISEREGVIOLATION,
  CAST(RAISE60SECVIOLATION AS DOUBLE) AS RAISE60SECVIOLATION,
  CAST(RAISE6SECVIOLATION AS DOUBLE) AS RAISE6SECVIOLATION,
  CAST(LOWER5MINVIOLATION AS DOUBLE) AS LOWER5MINVIOLATION,
  CAST(LOWERREGVIOLATION AS DOUBLE) AS LOWERREGVIOLATION,
  CAST(LOWER60SECVIOLATION AS DOUBLE) AS LOWER60SECVIOLATION,
  CAST(LOWER6SECVIOLATION AS DOUBLE) AS LOWER6SECVIOLATION,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  CAST(LORSURPLUS AS DOUBLE) AS LORSURPLUS,
  CAST(LRCSURPLUS AS DOUBLE) AS LRCSURPLUS,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:43:27.610481 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:43:27.619553 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: ROLLBACK
[0m09:43:27.641155 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price'
[0m09:43:27.641987 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price: Close
[0m09:43:27.645753 [debug] [Thread-1 (]: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.647030 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E97AB50>]}
[0m09:43:27.647030 [error] [Thread-1 (]: 3 of 7 ERROR creating sql incremental model aemo.fct_price ..................... [[31mERROR[0m in 0.10s]
[0m09:43:27.648300 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price
[0m09:43:27.649395 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_price_today
[0m09:43:27.650397 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:43:27.650397 [info ] [Thread-1 (]: 4 of 7 START sql incremental model aemo.fct_price_today ........................ [RUN]
[0m09:43:27.652386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price, now model.aemo_electricity.fct_price_today)
[0m09:43:27.653307 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_price_today
[0m09:43:27.722371 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_price_today"
[0m09:43:27.724470 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_price_today
[0m09:43:27.727374 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_price_today"
[0m09:43:27.729387 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:43:27.730403 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: BEGIN
[0m09:43:27.730403 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:27.732396 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:43:27.732396 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_price_today"
[0m09:43:27.733405 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:43:27.736843 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_price_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_price_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'price_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/price_today/day=' || substring(source_filename, 19, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

price_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'PRICE': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'RUNNO': 'VARCHAR',
      'REGIONID': 'VARCHAR',
      'DISPATCHINTERVAL': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'RRP': 'VARCHAR',
      'EEP': 'VARCHAR',
      'ROP': 'VARCHAR',
      'APCFLAG': 'VARCHAR',
      'MARKETSUSPENDEDFLAG': 'VARCHAR',
      'LASTCHANGED': 'VARCHAR',
      'RAISE6SECRRP': 'VARCHAR',
      'RAISE6SECROP': 'VARCHAR',
      'RAISE6SECAPCFLAG': 'VARCHAR',
      'RAISE60SECRRP': 'VARCHAR',
      'RAISE60SECROP': 'VARCHAR',
      'RAISE60SECAPCFLAG': 'VARCHAR',
      'RAISE5MINRRP': 'VARCHAR',
      'RAISE5MINROP': 'VARCHAR',
      'RAISE5MINAPCFLAG': 'VARCHAR',
      'RAISEREGRRP': 'VARCHAR',
      'RAISEREGROP': 'VARCHAR',
      'RAISEREGAPCFLAG': 'VARCHAR',
      'LOWER6SECRRP': 'VARCHAR',
      'LOWER6SECROP': 'VARCHAR',
      'LOWER6SECAPCFLAG': 'VARCHAR',
      'LOWER60SECRRP': 'VARCHAR',
      'LOWER60SECROP': 'VARCHAR',
      'LOWER60SECAPCFLAG': 'VARCHAR',
      'LOWER5MINRRP': 'VARCHAR',
      'LOWER5MINROP': 'VARCHAR',
      'LOWER5MINAPCFLAG': 'VARCHAR',
      'LOWERREGRRP': 'VARCHAR',
      'LOWERREGROP': 'VARCHAR',
      'LOWERREGAPCFLAG': 'VARCHAR',
      'PRICE_STATUS': 'VARCHAR',
      'PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'RAISE1SECRRP': 'VARCHAR',
      'RAISE1SECROP': 'VARCHAR',
      'RAISE1SECAPCFLAG': 'VARCHAR',
      'LOWER1SECRRP': 'VARCHAR',
      'LOWER1SECROP': 'VARCHAR',
      'LOWER1SECAPCFLAG': 'VARCHAR',
      'PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_ENERGY_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISEREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER6_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER60_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER5MIN_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWERREG_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_RAISE1_PRICE': 'VARCHAR',
      'CUMUL_PRE_AP_LOWER1_PRICE': 'VARCHAR',
      'OCD_STATUS': 'VARCHAR',
      'MII_STATUS': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND PRICE = 'PRICE'
)

SELECT
  REGIONID,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(DISPATCHINTERVAL AS DOUBLE) AS DISPATCHINTERVAL,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(RRP AS DOUBLE) AS RRP,
  CAST(EEP AS DOUBLE) AS EEP,
  CAST(ROP AS DOUBLE) AS ROP,
  CAST(APCFLAG AS DOUBLE) AS APCFLAG,
  CAST(MARKETSUSPENDEDFLAG AS DOUBLE) AS MARKETSUSPENDEDFLAG,
  CAST(RAISE6SECRRP AS DOUBLE) AS RAISE6SECRRP,
  CAST(RAISE6SECROP AS DOUBLE) AS RAISE6SECROP,
  CAST(RAISE6SECAPCFLAG AS DOUBLE) AS RAISE6SECAPCFLAG,
  CAST(RAISE60SECRRP AS DOUBLE) AS RAISE60SECRRP,
  CAST(RAISE60SECROP AS DOUBLE) AS RAISE60SECROP,
  CAST(RAISE60SECAPCFLAG AS DOUBLE) AS RAISE60SECAPCFLAG,
  CAST(RAISE5MINRRP AS DOUBLE) AS RAISE5MINRRP,
  CAST(RAISE5MINROP AS DOUBLE) AS RAISE5MINROP,
  CAST(RAISE5MINAPCFLAG AS DOUBLE) AS RAISE5MINAPCFLAG,
  CAST(RAISEREGRRP AS DOUBLE) AS RAISEREGRRP,
  CAST(RAISEREGROP AS DOUBLE) AS RAISEREGROP,
  CAST(RAISEREGAPCFLAG AS DOUBLE) AS RAISEREGAPCFLAG,
  CAST(LOWER6SECRRP AS DOUBLE) AS LOWER6SECRRP,
  CAST(LOWER6SECROP AS DOUBLE) AS LOWER6SECROP,
  CAST(LOWER6SECAPCFLAG AS DOUBLE) AS LOWER6SECAPCFLAG,
  CAST(LOWER60SECRRP AS DOUBLE) AS LOWER60SECRRP,
  CAST(LOWER60SECROP AS DOUBLE) AS LOWER60SECROP,
  CAST(LOWER60SECAPCFLAG AS DOUBLE) AS LOWER60SECAPCFLAG,
  CAST(LOWER5MINRRP AS DOUBLE) AS LOWER5MINRRP,
  CAST(LOWER5MINROP AS DOUBLE) AS LOWER5MINROP,
  CAST(LOWER5MINAPCFLAG AS DOUBLE) AS LOWER5MINAPCFLAG,
  CAST(LOWERREGRRP AS DOUBLE) AS LOWERREGRRP,
  CAST(LOWERREGROP AS DOUBLE) AS LOWERREGROP,
  CAST(LOWERREGAPCFLAG AS DOUBLE) AS LOWERREGAPCFLAG,
  CAST(PRE_AP_ENERGY_PRICE AS DOUBLE) AS PRE_AP_ENERGY_PRICE,
  CAST(PRE_AP_RAISE6_PRICE AS DOUBLE) AS PRE_AP_RAISE6_PRICE,
  CAST(PRE_AP_RAISE60_PRICE AS DOUBLE) AS PRE_AP_RAISE60_PRICE,
  CAST(PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS PRE_AP_RAISE5MIN_PRICE,
  CAST(PRE_AP_RAISEREG_PRICE AS DOUBLE) AS PRE_AP_RAISEREG_PRICE,
  CAST(PRE_AP_LOWER6_PRICE AS DOUBLE) AS PRE_AP_LOWER6_PRICE,
  CAST(PRE_AP_LOWER60_PRICE AS DOUBLE) AS PRE_AP_LOWER60_PRICE,
  CAST(PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS PRE_AP_LOWER5MIN_PRICE,
  CAST(PRE_AP_LOWERREG_PRICE AS DOUBLE) AS PRE_AP_LOWERREG_PRICE,
  CAST(RAISE1SECRRP AS DOUBLE) AS RAISE1SECRRP,
  CAST(RAISE1SECROP AS DOUBLE) AS RAISE1SECROP,
  CAST(RAISE1SECAPCFLAG AS DOUBLE) AS RAISE1SECAPCFLAG,
  CAST(LOWER1SECRRP AS DOUBLE) AS LOWER1SECRRP,
  CAST(LOWER1SECROP AS DOUBLE) AS LOWER1SECROP,
  CAST(LOWER1SECAPCFLAG AS DOUBLE) AS LOWER1SECAPCFLAG,
  CAST(PRE_AP_RAISE1_PRICE AS DOUBLE) AS PRE_AP_RAISE1_PRICE,
  CAST(PRE_AP_LOWER1_PRICE AS DOUBLE) AS PRE_AP_LOWER1_PRICE,
  CAST(CUMUL_PRE_AP_ENERGY_PRICE AS DOUBLE) AS CUMUL_PRE_AP_ENERGY_PRICE,
  CAST(CUMUL_PRE_AP_RAISE6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE6_PRICE,
  CAST(CUMUL_PRE_AP_RAISE60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE60_PRICE,
  CAST(CUMUL_PRE_AP_RAISE5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE5MIN_PRICE,
  CAST(CUMUL_PRE_AP_RAISEREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISEREG_PRICE,
  CAST(CUMUL_PRE_AP_LOWER6_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER6_PRICE,
  CAST(CUMUL_PRE_AP_LOWER60_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER60_PRICE,
  CAST(CUMUL_PRE_AP_LOWER5MIN_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER5MIN_PRICE,
  CAST(CUMUL_PRE_AP_LOWERREG_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWERREG_PRICE,
  CAST(CUMUL_PRE_AP_RAISE1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_RAISE1_PRICE,
  CAST(CUMUL_PRE_AP_LOWER1_PRICE AS DOUBLE) AS CUMUL_PRE_AP_LOWER1_PRICE,
  SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM price_staging
    );
  
  
  
[0m09:43:27.736843 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:43:27.736843 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: ROLLBACK
[0m09:43:27.736843 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_price_today'
[0m09:43:27.736843 [debug] [Thread-1 (]: On model.aemo_electricity.fct_price_today: Close
[0m09:43:27.736843 [debug] [Thread-1 (]: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.736843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E9666D0>]}
[0m09:43:27.736843 [error] [Thread-1 (]: 4 of 7 ERROR creating sql incremental model aemo.fct_price_today ............... [[31mERROR[0m in 0.08s]
[0m09:43:27.736843 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_price_today
[0m09:43:27.752606 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada
[0m09:43:27.752606 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_price_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:43:27.752606 [info ] [Thread-1 (]: 5 of 7 START sql incremental model aemo.fct_scada .............................. [RUN]
[0m09:43:27.755261 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_price_today, now model.aemo_electricity.fct_scada)
[0m09:43:27.755261 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada
[0m09:43:27.760401 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada"
[0m09:43:27.761909 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada
[0m09:43:27.766076 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada"
[0m09:43:27.767972 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:43:27.767972 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: BEGIN
[0m09:43:27.767972 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:27.771160 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:43:27.772094 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada"
[0m09:43:27.773102 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:43:27.781539 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'daily'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/daily/year=' || substring(source_filename, 14, 4) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'UNIT': 'VARCHAR',
      'XX': 'VARCHAR',
      'VERSION': 'VARCHAR',
      'SETTLEMENTDATE': 'VARCHAR',
      'RUNNO': 'VARCHAR',
      'DUID': 'VARCHAR',
      'INTERVENTION': 'VARCHAR',
      'DISPATCHMODE': 'VARCHAR',
      'AGCSTATUS': 'VARCHAR',
      'INITIALMW': 'VARCHAR',
      'TOTALCLEARED': 'VARCHAR',
      'RAMPDOWNRATE': 'VARCHAR',
      'RAMPUPRATE': 'VARCHAR',
      'LOWER5MIN': 'VARCHAR',
      'LOWER60SEC': 'VARCHAR',
      'LOWER6SEC': 'VARCHAR',
      'RAISE5MIN': 'VARCHAR',
      'RAISE60SEC': 'VARCHAR',
      'RAISE6SEC': 'VARCHAR',
      'MARGINAL5MINVALUE': 'VARCHAR',
      'MARGINAL60SECVALUE': 'VARCHAR',
      'MARGINAL6SECVALUE': 'VARCHAR',
      'MARGINALVALUE': 'VARCHAR',
      'VIOLATION5MINDEGREE': 'VARCHAR',
      'VIOLATION60SECDEGREE': 'VARCHAR',
      'VIOLATION6SECDEGREE': 'VARCHAR',
      'VIOLATIONDEGREE': 'VARCHAR',
      'LOWERREG': 'VARCHAR',
      'RAISEREG': 'VARCHAR',
      'AVAILABILITY': 'VARCHAR',
      'RAISE6SECFLAGS': 'VARCHAR',
      'RAISE60SECFLAGS': 'VARCHAR',
      'RAISE5MINFLAGS': 'VARCHAR',
      'RAISEREGFLAGS': 'VARCHAR',
      'LOWER6SECFLAGS': 'VARCHAR',
      'LOWER60SECFLAGS': 'VARCHAR',
      'LOWER5MINFLAGS': 'VARCHAR',
      'LOWERREGFLAGS': 'VARCHAR',
      'RAISEREGAVAILABILITY': 'VARCHAR',
      'RAISEREGENABLEMENTMAX': 'VARCHAR',
      'RAISEREGENABLEMENTMIN': 'VARCHAR',
      'LOWERREGAVAILABILITY': 'VARCHAR',
      'LOWERREGENABLEMENTMAX': 'VARCHAR',
      'LOWERREGENABLEMENTMIN': 'VARCHAR',
      'RAISE6SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE60SECACTUALAVAILABILITY': 'VARCHAR',
      'RAISE5MINACTUALAVAILABILITY': 'VARCHAR',
      'RAISEREGACTUALAVAILABILITY': 'VARCHAR',
      'LOWER6SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER60SECACTUALAVAILABILITY': 'VARCHAR',
      'LOWER5MINACTUALAVAILABILITY': 'VARCHAR',
      'LOWERREGACTUALAVAILABILITY': 'VARCHAR'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND UNIT = 'DUNIT' AND VERSION = '3'
)

SELECT
  UNIT,
  DUID,
  CAST(VERSION AS DOUBLE) AS VERSION,
  CAST(RUNNO AS DOUBLE) AS RUNNO,
  CAST(INTERVENTION AS DOUBLE) AS INTERVENTION,
  CAST(DISPATCHMODE AS DOUBLE) AS DISPATCHMODE,
  CAST(AGCSTATUS AS DOUBLE) AS AGCSTATUS,
  CAST(INITIALMW AS DOUBLE) AS INITIALMW,
  CAST(TOTALCLEARED AS DOUBLE) AS TOTALCLEARED,
  CAST(RAMPDOWNRATE AS DOUBLE) AS RAMPDOWNRATE,
  CAST(RAMPUPRATE AS DOUBLE) AS RAMPUPRATE,
  CAST(LOWER5MIN AS DOUBLE) AS LOWER5MIN,
  CAST(LOWER60SEC AS DOUBLE) AS LOWER60SEC,
  CAST(LOWER6SEC AS DOUBLE) AS LOWER6SEC,
  CAST(RAISE5MIN AS DOUBLE) AS RAISE5MIN,
  CAST(RAISE60SEC AS DOUBLE) AS RAISE60SEC,
  CAST(RAISE6SEC AS DOUBLE) AS RAISE6SEC,
  CAST(MARGINAL5MINVALUE AS DOUBLE) AS MARGINAL5MINVALUE,
  CAST(MARGINAL60SECVALUE AS DOUBLE) AS MARGINAL60SECVALUE,
  CAST(MARGINAL6SECVALUE AS DOUBLE) AS MARGINAL6SECVALUE,
  CAST(MARGINALVALUE AS DOUBLE) AS MARGINALVALUE,
  CAST(VIOLATION5MINDEGREE AS DOUBLE) AS VIOLATION5MINDEGREE,
  CAST(VIOLATION60SECDEGREE AS DOUBLE) AS VIOLATION60SECDEGREE,
  CAST(VIOLATION6SECDEGREE AS DOUBLE) AS VIOLATION6SECDEGREE,
  CAST(VIOLATIONDEGREE AS DOUBLE) AS VIOLATIONDEGREE,
  CAST(LOWERREG AS DOUBLE) AS LOWERREG,
  CAST(RAISEREG AS DOUBLE) AS RAISEREG,
  CAST(AVAILABILITY AS DOUBLE) AS AVAILABILITY,
  CAST(RAISE6SECFLAGS AS DOUBLE) AS RAISE6SECFLAGS,
  CAST(RAISE60SECFLAGS AS DOUBLE) AS RAISE60SECFLAGS,
  CAST(RAISE5MINFLAGS AS DOUBLE) AS RAISE5MINFLAGS,
  CAST(RAISEREGFLAGS AS DOUBLE) AS RAISEREGFLAGS,
  CAST(LOWER6SECFLAGS AS DOUBLE) AS LOWER6SECFLAGS,
  CAST(LOWER60SECFLAGS AS DOUBLE) AS LOWER60SECFLAGS,
  CAST(LOWER5MINFLAGS AS DOUBLE) AS LOWER5MINFLAGS,
  CAST(LOWERREGFLAGS AS DOUBLE) AS LOWERREGFLAGS,
  CAST(RAISEREGAVAILABILITY AS DOUBLE) AS RAISEREGAVAILABILITY,
  CAST(RAISEREGENABLEMENTMAX AS DOUBLE) AS RAISEREGENABLEMENTMAX,
  CAST(RAISEREGENABLEMENTMIN AS DOUBLE) AS RAISEREGENABLEMENTMIN,
  CAST(LOWERREGAVAILABILITY AS DOUBLE) AS LOWERREGAVAILABILITY,
  CAST(LOWERREGENABLEMENTMAX AS DOUBLE) AS LOWERREGENABLEMENTMAX,
  CAST(LOWERREGENABLEMENTMIN AS DOUBLE) AS LOWERREGENABLEMENTMIN,
  CAST(RAISE6SECACTUALAVAILABILITY AS DOUBLE) AS RAISE6SECACTUALAVAILABILITY,
  CAST(RAISE60SECACTUALAVAILABILITY AS DOUBLE) AS RAISE60SECACTUALAVAILABILITY,
  CAST(RAISE5MINACTUALAVAILABILITY AS DOUBLE) AS RAISE5MINACTUALAVAILABILITY,
  CAST(RAISEREGACTUALAVAILABILITY AS DOUBLE) AS RAISEREGACTUALAVAILABILITY,
  CAST(LOWER6SECACTUALAVAILABILITY AS DOUBLE) AS LOWER6SECACTUALAVAILABILITY,
  CAST(LOWER60SECACTUALAVAILABILITY AS DOUBLE) AS LOWER60SECACTUALAVAILABILITY,
  CAST(LOWER5MINACTUALAVAILABILITY AS DOUBLE) AS LOWER5MINACTUALAVAILABILITY,
  CAST(LOWERREGACTUALAVAILABILITY AS DOUBLE) AS LOWERREGACTUALAVAILABILITY,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  CAST(SETTLEMENTDATE AS TIMESTAMP) AS SETTLEMENTDATE,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(CAST(SETTLEMENTDATE AS TIMESTAMP)) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:43:27.782225 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:43:27.782225 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: ROLLBACK
[0m09:43:27.787939 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada'
[0m09:43:27.787939 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada: Close
[0m09:43:27.787939 [debug] [Thread-1 (]: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.787939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3E137750>]}
[0m09:43:27.795106 [error] [Thread-1 (]: 5 of 7 ERROR creating sql incremental model aemo.fct_scada ..................... [[31mERROR[0m in 0.03s]
[0m09:43:27.796112 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada
[0m09:43:27.797200 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_scada_today
[0m09:43:27.797200 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:43:27.798244 [info ] [Thread-1 (]: 6 of 7 START sql incremental model aemo.fct_scada_today ........................ [RUN]
[0m09:43:27.798756 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.aemo_electricity.fct_scada, now model.aemo_electricity.fct_scada_today)
[0m09:43:27.799762 [debug] [Thread-1 (]: Began compiling node model.aemo_electricity.fct_scada_today
[0m09:43:27.803798 [debug] [Thread-1 (]: Writing injected SQL for node "model.aemo_electricity.fct_scada_today"
[0m09:43:27.806505 [debug] [Thread-1 (]: Began executing node model.aemo_electricity.fct_scada_today
[0m09:43:27.810669 [debug] [Thread-1 (]: Writing runtime sql for node "model.aemo_electricity.fct_scada_today"
[0m09:43:27.812743 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:43:27.813593 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: BEGIN
[0m09:43:27.814600 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:27.815716 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m09:43:27.816600 [debug] [Thread-1 (]: Using duckdb connection "model.aemo_electricity.fct_scada_today"
[0m09:43:27.816600 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:43:27.821811 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "aemo_electricity", "target_name": "dev", "node_id": "model.aemo_electricity.fct_scada_today"} */

  
    
    

    create  table
      "ducklake"."aemo"."fct_scada_today"
  
    as (
      



WITH source_files AS (
  SELECT source_filename
  FROM "ducklake"."aemo"."csv_archive_log"
  WHERE source_type = 'scada_today'
  
),

file_paths AS (
  SELECT list('zip://' || '/lakehouse/default/Files/csv' || '/scada_today/day=' || substring(source_filename, 22, 8) || '/source_file=' || source_filename || '/data_0.zip/*.CSV') as paths
  FROM source_files
),

scada_staging AS (
  SELECT *
  FROM read_csv(
    (SELECT COALESCE(paths, ['']) FROM file_paths),
    skip = 1,
    header = 0,
    all_varchar = 1,
    columns = {
      'I': 'VARCHAR',
      'DISPATCH': 'VARCHAR',
      'UNIT_SCADA': 'VARCHAR',
      'xx': 'VARCHAR',
      'SETTLEMENTDATE': 'timestamp',
      'DUID': 'VARCHAR',
      'SCADAVALUE': 'double',
      'LASTCHANGED': 'timestamp'
    },
    filename = 1,
    null_padding = true,
    ignore_errors = 1,
    auto_detect = false,
    hive_partitioning = false
  )
  WHERE I = 'D' AND SCADAVALUE != 0
)

SELECT
  DUID,
  SCADAVALUE AS INITIALMW,
  
    split_part(split_part(filename, '/', -1), '.', 1)
 AS file,
  SETTLEMENTDATE,
  LASTCHANGED,
  CAST(SETTLEMENTDATE AS DATE) AS DATE,
  CAST(YEAR(SETTLEMENTDATE) AS INT) AS YEAR
FROM scada_staging
    );
  
  
  
[0m09:43:27.821811 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m09:43:27.821811 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: ROLLBACK
[0m09:43:27.829987 [debug] [Thread-1 (]: Failed to rollback 'model.aemo_electricity.fct_scada_today'
[0m09:43:27.829987 [debug] [Thread-1 (]: On model.aemo_electricity.fct_scada_today: Close
[0m09:43:27.829987 [debug] [Thread-1 (]: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.829987 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe2f4460-c811-43c3-a54a-8b6a00401f7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC3AB44C90>]}
[0m09:43:27.829987 [error] [Thread-1 (]: 6 of 7 ERROR creating sql incremental model aemo.fct_scada_today ............... [[31mERROR[0m in 0.03s]
[0m09:43:27.837994 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_scada_today
[0m09:43:27.837994 [debug] [Thread-1 (]: Began running node model.aemo_electricity.fct_summary
[0m09:43:27.839078 [debug] [Thread-4 (]: Marking all children of 'model.aemo_electricity.fct_scada_today' to be skipped because of status 'error'.  Reason: Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^.
[0m09:43:27.839078 [info ] [Thread-1 (]: 7 of 7 SKIP relation aemo.fct_summary .......................................... [[33mSKIP[0m]
[0m09:43:27.840115 [debug] [Thread-1 (]: Finished running node model.aemo_electricity.fct_summary
[0m09:43:27.841881 [debug] [MainThread]: Using duckdb connection "master"
[0m09:43:27.842886 [debug] [MainThread]: On master: BEGIN
[0m09:43:27.842886 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:43:27.844886 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m09:43:27.845265 [debug] [MainThread]: On master: COMMIT
[0m09:43:27.845972 [debug] [MainThread]: Using duckdb connection "master"
[0m09:43:27.845972 [debug] [MainThread]: On master: COMMIT
[0m09:43:27.847017 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m09:43:27.847017 [debug] [MainThread]: On master: Close
[0m09:43:27.848017 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:43:27.849041 [debug] [MainThread]: Connection 'create_ducklake_aemo' was properly closed.
[0m09:43:27.849041 [debug] [MainThread]: Connection 'list_ducklake_aemo' was properly closed.
[0m09:43:27.850016 [debug] [MainThread]: Connection 'model.aemo_electricity.fct_scada_today' was properly closed.
[0m09:43:27.850016 [info ] [MainThread]: 
[0m09:43:27.851015 [info ] [MainThread]: Finished running 5 incremental models, 1 project hook, 2 table models in 0 hours 0 minutes and 57.58 seconds (57.58s).
[0m09:43:27.853032 [debug] [MainThread]: Command end result
[0m09:43:27.873681 [debug] [MainThread]: Wrote artifact WritableManifest to C:\lakehouse\default\Files\dbt\target\manifest.json
[0m09:43:27.887017 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\lakehouse\default\Files\dbt\target\semantic_manifest.json
[0m09:43:27.894023 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\lakehouse\default\Files\dbt\target\run_results.json
[0m09:43:27.894023 [info ] [MainThread]: 
[0m09:43:27.895023 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m09:43:27.896245 [info ] [MainThread]: 
[0m09:43:27.897188 [error] [MainThread]: [31mFailure in model fct_price (models\marts\fct_price.sql)[0m
[0m09:43:27.898263 [error] [MainThread]:   Runtime Error in model fct_price (models\marts\fct_price.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.899189 [info ] [MainThread]: 
[0m09:43:27.900190 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price.sql
[0m09:43:27.901187 [info ] [MainThread]: 
[0m09:43:27.902193 [error] [MainThread]: [31mFailure in model fct_price_today (models\marts\fct_price_today.sql)[0m
[0m09:43:27.903191 [error] [MainThread]:   Runtime Error in model fct_price_today (models\marts\fct_price_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.903578 [info ] [MainThread]: 
[0m09:43:27.904603 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_price_today.sql
[0m09:43:27.906026 [info ] [MainThread]: 
[0m09:43:27.906026 [error] [MainThread]: [31mFailure in model fct_scada (models\marts\fct_scada.sql)[0m
[0m09:43:27.907989 [error] [MainThread]:   Runtime Error in model fct_scada (models\marts\fct_scada.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.909033 [info ] [MainThread]: 
[0m09:43:27.910537 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada.sql
[0m09:43:27.911546 [info ] [MainThread]: 
[0m09:43:27.912089 [error] [MainThread]: [31mFailure in model fct_scada_today (models\marts\fct_scada_today.sql)[0m
[0m09:43:27.912089 [error] [MainThread]:   Runtime Error in model fct_scada_today (models\marts\fct_scada_today.sql)
  Catalog Error: Table with name csv_archive_log does not exist!
  Did you mean "dim_calendar"?
  
  LINE 17:   FROM "ducklake"."aemo"."csv_archive_log"
                  ^
[0m09:43:27.912089 [info ] [MainThread]: 
[0m09:43:27.912089 [info ] [MainThread]:   compiled code at target\compiled\aemo_electricity\models\marts\fct_scada_today.sql
[0m09:43:27.912089 [info ] [MainThread]: 
[0m09:43:27.917696 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=4 SKIP=1 NO-OP=0 TOTAL=8
[0m09:43:27.919026 [debug] [MainThread]: Command `dbt run` failed at 09:43:27.919026 after 60.35 seconds
[0m09:43:27.920573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC366D0710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC36502650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC36502410>]}
[0m09:43:27.920573 [debug] [MainThread]: Flushing usage events
[0m09:43:29.197634 [debug] [MainThread]: An error was encountered while trying to flush usage events
